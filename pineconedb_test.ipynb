{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building and Implementing Pinecone Vector Databases\n",
    "#https://www.analyticsvidhya.com/blog/2024/06/pinecone-vector-databases/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pinecone langchain langchain_pinecone langchain-openai langchain-community pypdf python-dotenv\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter # To split the text into smaller chunks\n",
    "from langchain_openai import OpenAIEmbeddings # To create embeddings\n",
    "from langchain_pinecone import PineconeVectorStore # To connect with the Vectorstore\n",
    "from langchain_community.document_loaders import DirectoryLoader # To load files in a directory\n",
    "from langchain_community.document_loaders import PyPDFLoader # To parse the PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3, Environment Setup\n",
    "#Load API keys:\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your OpenAI API Key\"\n",
    "os.environ[\"PINECONE_API_KEY\"] = \"your pinecone api key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pinecone.control.pinecone.Pinecone at 0x1c27f3074c0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4, Pinecone Configuration\n",
    "index_name = \"pinecone-index-test1\" #give the name to your index, or you can use an index which you created previously and load that.\n",
    "#here we are using the new fresh index name\n",
    "pc = Pinecone(api_key=\"1e14ea53-ac97-4bc3-9b6a-06c83608e0fb\")\n",
    "#Get your Pinecone API key to connect after successful login and put it here.\n",
    "pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index created\n",
      "{'dimension': 1536,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {},\n",
      " 'total_vector_count': 0}\n"
     ]
    }
   ],
   "source": [
    "#Index Creation or Loading\n",
    "pc.create_index(\n",
    "  name=index_name,\n",
    "  dimension=1536, # Replace with your model dimensions\n",
    "  metric=\"cosine\", # Replace with your model metric\n",
    "  spec=ServerlessSpec(cloud=\"aws\",\n",
    "       region=\"us-east-1\"\n",
    "   )\n",
    ")\n",
    "while not pc.describe_index(index_name).status[\"ready\"]:\n",
    "    time.sleep(1)\n",
    "index= pc.Index(index_name)\n",
    "print(\"index created\")\n",
    "print(index.describe_index_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5: Data Preparation and Loading for Vector Database Ingestion\n",
    "#Setting Key Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR_PATH = \"./documents\"  # \"/content/drive/MyDrive/Data\", Directory containing our PDF files\n",
    "CHUNK_SIZE = 1024  # Size of each text chunk for processing\n",
    "CHUNK_OVERLAP = 0  # Amount of overlap between chunks\n",
    "INDEX_NAME = index_name  # Name of our Pinecone index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading PDF Documents\n",
    "#To load our PDF files, we’ll use LangChain’s DirectoryLoader in conjunction with the PyPDFLoader. \n",
    "# This combination allows us to efficiently process multiple PDF files from a specified directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Documents loaded: 2\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, PyPDFLoader\n",
    "loader = DirectoryLoader(\n",
    "    path=DATA_DIR_PATH,  # Directory containing our PDFs\n",
    "    glob=\"**/*.pdf\",     # Pattern to match PDF files (including subdirectories)\n",
    "    loader_cls=PyPDFLoader  # Specifies we're loading PDF files\n",
    ")\n",
    "docs = loader.load()  # This loads all matching PDF files\n",
    "print(f\"Total Documents loaded: {len(docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'documents\\\\AILead.pdf', 'page': 0}, page_content='AI Lead  \\nWhat You Will Be Doing  \\nAs a key member of a leading provider of technology -enabled revenue cycle \\nmanagement solutions for health systems, you will be responsible for building AI and \\nMachine learning models and pipelines, with a focus on generative AI, LLMs, and \\npredictive modeli ng. Your role will involve collaborating closely with business owners to \\nunderstand their data requirements and product specifications, enabling them to make \\ninformed data -related decisions and product design choices.  \\n Additionally, you will work alongside data scientists, software engineers, and \\ndevelopers to deliver innovative solutions. Defining strategic priorities for AI and GenAI \\ndevelopment across the company and educating both technical and business teams on \\nthe latest AI advancements will be crucial aspects of your role. You may also need to \\nquickly adapt to new tools and technologies, supported by your deep ML/A1 knowledge \\nand basic programming skills.  \\n \\nWhat The Company Hiring Is Looking For  \\nThe ideal candidate will have expertise in designing, developing, managing, and \\nmaintaining systems, as wells as handling large datasets. You should possess hands -on \\nexperience with common machine learning and AI frameworks, a solid understanding of \\nAI and machine learning fundamentals, and a good grasp of LLM -supported use cases.  \\nYour responsibilities will include designing, developing, and overseeing the \\nimplementation of end -to-end AI solutions, ensuring alignment with business \\noutcomes, and fostering interoperability between client systems, internal teams, and \\nthird-party vendor s. Educating team members on recent AI trends, presenting key \\nfindings, evaluating predictive models, and contributing to the strategic direction of AI \\ninitiatives within the company are also key responsibilities.  \\n \\nQualities/Skills The Company Hiring Is Looking For  \\n• 5+ years of experience leading a data science/machine learning team . \\n• PhD or MSc in Computer Science/Machine Learning/A1, or related work \\nexperienc e. \\n• Proficiency with Machine Learning ecosystem tools such as PyTorch/Tensorflow, \\nscikit-learn, xgboost . \\n• Ability to research and implement solutions based on novel algorithms . \\n ')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.documents.base.Document"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys associated with a Document: dict_keys(['id', 'metadata', 'page_content', 'type'])\n"
     ]
    }
   ],
   "source": [
    "# we can convert the Document object to a python dict using the .dict() method.\n",
    "print(f\"keys associated with a Document: {docs[0].dict().keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------\n",
      "First 100 charachters of the page content: • Experience with LLM -based pipelines and retrieval augmented generation \n",
      "techniques is a plus . \n",
      "•\n",
      "---------------\n",
      "Metadata associated with the document: {'source': 'documents\\\\AILead.pdf', 'page': 1}\n",
      "---------------\n",
      "Datatype of the document: Document\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "print(f\"{'-'*15}\\nFirst 100 charachters of the page content: {docs[1].page_content[:100]}\\n{'-'*15}\")\n",
    "print(f\"Metadata associated with the document: {docs[1].metadata}\\n{'-'*15}\")\n",
    "print(f\"Datatype of the document: {docs[1].type}\\n{'-'*15}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata associated with the document: {'filename': 'AILead.pdf', 'source': 'documents\\\\AILead.pdf', 'page': 0}\n",
      "---------------\n",
      "Metadata associated with the document: {'filename': 'AILead.pdf', 'source': 'documents\\\\AILead.pdf', 'page': 1}\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "#  We loop through each document and add additional metadata - filename, quarter, and year\n",
    "for doc in docs:\n",
    "   filename = doc.dict()['metadata']['source'].split(\"\\\\\")[-1]\n",
    "   #quarter = doc.dict()['metadata']['source'].split(\"\\\\\")[-2]\n",
    "   #year = doc.dict()['metadata']['source'].split(\"\\\\\")[-3]\n",
    "   doc.metadata = {\"filename\": filename, \"source\": doc.dict()['metadata']['source'], \"page\": doc.dict()['metadata']['page']}\n",
    "\n",
    "# To veryfy that the metadata is indeed added to the document\n",
    "print(f\"Metadata associated with the document: {docs[0].metadata}\\n{'-'*15}\")\n",
    "print(f\"Metadata associated with the document: {docs[1].metadata}\\n{'-'*15}\")\n",
    "#print(f\"Metadata associated with the document: {docs[2].metadata}\\n{'-'*15}\")\n",
    "#print(f\"Metadata associated with the document: {docs[3].metadata}\\n{'-'*15}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata associated with the document: {'filename': 'AILead.pdf', 'source': 'documents\\\\AILead.pdf', 'page': 0}\n",
      "---------------\n",
      "Metadata associated with the document: {'filename': 'AILead.pdf', 'source': 'documents\\\\AILead.pdf', 'page': 1}\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(docs)) :\n",
    "  print(f\"Metadata associated with the document: {docs[i].metadata}\\n{'-'*15}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6: Optimizing Data for Vector Databases\n",
    "#Recursive Character Chunking, a method that balances efficiency with content coherence. \n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1024,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "documents = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 5)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split text into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=CHUNK_OVERLAP\n",
    ")\n",
    "documents = text_splitter.split_documents(docs)\n",
    "len(docs), len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAIEmbeddings(client=<openai.resources.embeddings.Embeddings object at 0x000001C20C00F1F0>, async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x000001C20C02C790>, model='text-embedding-ada-002', dimensions=None, deployment='text-embedding-ada-002', openai_api_version='', openai_api_base=None, openai_api_type='', openai_proxy='', embedding_ctx_length=8191, openai_api_key=SecretStr('**********'), openai_organization=None, allowed_special=None, disallowed_special=None, chunk_size=1000, max_retries=2, request_timeout=None, headers=None, tiktoken_enabled=True, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={}, skip_empty=False, default_headers=None, default_query=None, retry_min_seconds=4, retry_max_seconds=20, http_client=None, http_async_client=None, check_embedding_ctx_length=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step7: Embedding and Vector Store Creation\n",
    "embeddings = OpenAIEmbeddings(model = \"text-embedding-ada-002\") # Initialize the embedding model\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New vectorstore is created and loaded\n"
     ]
    }
   ],
   "source": [
    "docs_already_in_pinecone = \"N\" #input(\"Are the vectors already added in DB: N\")\n",
    "# check if the documents were already added to the vector database\n",
    "if docs_already_in_pinecone == \"Y\" or docs_already_in_pinecone == \"y\":\n",
    "   docsearch = PineconeVectorStore(index_name=INDEX_NAME, embedding=embeddings)\n",
    "   print(\"Existing Vectorstore is loaded\")\n",
    "# if not then add the documents to the vectore db\n",
    "elif docs_already_in_pinecone == \"N\" or docs_already_in_pinecone == \"n\":\n",
    "   docsearch = PineconeVectorStore.from_documents(documents, embeddings, index_name=index_name)\n",
    "   print(\"New vectorstore is created and loaded\")\n",
    "else:\n",
    "   print(\"Please type Y - for yes and N - for no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'filename': 'AILead.pdf', 'page': 1.0, 'source': 'documents\\\\AILead.pdf'}, page_content='and machine learning.'),\n",
       " Document(metadata={'filename': 'AILead.pdf', 'page': 0.0, 'source': 'documents\\\\AILead.pdf'}, page_content='experienc e. \\n• Proficiency with Machine Learning ecosystem tools such as PyTorch/Tensorflow, \\nscikit-learn, xgboost . \\n• Ability to research and implement solutions based on novel algorithms .'),\n",
       " Document(metadata={'filename': 'AILead.pdf', 'page': 1.0, 'source': 'documents\\\\AILead.pdf'}, page_content='• Experience with LLM -based pipelines and retrieval augmented generation \\ntechniques is a plus . \\n• Familiarity with tools like langchain/llamaindex/haystack/Azure AI studio . \\n• Proficiency in SQL, Azure Data Factory, or similar for database handling . \\n• Knowledge of Software Development best practices and MLOps fundamentals . \\n• Ability to work independently and in a fast -paced team environment . \\n• Excellent written and verbal communication skills . \\n \\nJoin a dynamic team at the forefront of technology -enabled revenue cycle management \\nsolutions for health systems. You will have the opportunity to lead AI initiatives, work on \\ncutting-edge projects, and collaborate with talented professionals in a supporti ve and \\ninnovative environment.  \\nAdditionally, you will receive a competitive salary, benefits package, and opportunities \\nfor professional growth and development. Apply now to be part of a company dedicated \\nto keeping communities healthy by keeping hospitals healthy through the power of A I'),\n",
       " Document(metadata={'filename': 'AILead.pdf', 'page': 0.0, 'source': 'documents\\\\AILead.pdf'}, page_content='The ideal candidate will have expertise in designing, developing, managing, and \\nmaintaining systems, as wells as handling large datasets. You should possess hands -on \\nexperience with common machine learning and AI frameworks, a solid understanding of \\nAI and machine learning fundamentals, and a good grasp of LLM -supported use cases.  \\nYour responsibilities will include designing, developing, and overseeing the \\nimplementation of end -to-end AI solutions, ensuring alignment with business \\noutcomes, and fostering interoperability between client systems, internal teams, and \\nthird-party vendor s. Educating team members on recent AI trends, presenting key \\nfindings, evaluating predictive models, and contributing to the strategic direction of AI \\ninitiatives within the company are also key responsibilities.  \\n \\nQualities/Skills The Company Hiring Is Looking For  \\n• 5+ years of experience leading a data science/machine learning team . \\n• PhD or MSc in Computer Science/Machine Learning/A1, or related work')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using the Vector Store for Retrieval\n",
    "# Here we are defing how to use the loaded vectorstore as retriver\n",
    "retriver = docsearch.as_retriever()\n",
    "retriver.invoke(\"what does the team looks like?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
