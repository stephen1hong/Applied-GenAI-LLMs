{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65b0579f-5169-48cc-bf67-24084295a032",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import streamlit as st\n",
    "import pickle\n",
    "import langchain\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.chains.qa_with_sources.loading import load_qa_with_sources_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import UnstructuredURLLoader\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bad5be4a-b760-475c-ba94-eddcd14dd06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting InstructorEmbedding\n",
      "  Downloading InstructorEmbedding-1.0.1-py2.py3-none-any.whl.metadata (20 kB)\n",
      "Downloading InstructorEmbedding-1.0.1-py2.py3-none-any.whl (19 kB)\n",
      "Installing collected packages: InstructorEmbedding\n",
      "Successfully installed InstructorEmbedding-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install InstructorEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8150042b-17ff-4643-9d3c-feb1b4ec87d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement langchian-community (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for langchian-community\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip  install -U langchian-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65b22db1-76fb-42cc-85be-895ec2b85f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /home/techlab/myenv/lib/python3.10/site-packages (2.7.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /home/techlab/myenv/lib/python3.10/site-packages (from sentence-transformers) (4.40.0)\n",
      "Requirement already satisfied: tqdm in /home/techlab/myenv/lib/python3.10/site-packages (from sentence-transformers) (4.66.2)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/techlab/myenv/lib/python3.10/site-packages (from sentence-transformers) (2.2.1)\n",
      "Requirement already satisfied: numpy in /home/techlab/myenv/lib/python3.10/site-packages (from sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /home/techlab/myenv/lib/python3.10/site-packages (from sentence-transformers) (1.4.1.post1)\n",
      "Requirement already satisfied: scipy in /home/techlab/myenv/lib/python3.10/site-packages (from sentence-transformers) (1.12.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /home/techlab/myenv/lib/python3.10/site-packages (from sentence-transformers) (0.22.2)\n",
      "Requirement already satisfied: Pillow in /home/techlab/myenv/lib/python3.10/site-packages (from sentence-transformers) (10.2.0)\n",
      "Requirement already satisfied: filelock in /home/techlab/myenv/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/techlab/myenv/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/techlab/myenv/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/techlab/myenv/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /home/techlab/myenv/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/techlab/myenv/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.10.0)\n",
      "Requirement already satisfied: sympy in /home/techlab/myenv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /home/techlab/myenv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/techlab/myenv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/techlab/myenv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/techlab/myenv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/techlab/myenv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/techlab/myenv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/techlab/myenv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/techlab/myenv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/techlab/myenv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/techlab/myenv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/techlab/myenv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/techlab/myenv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/techlab/myenv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/techlab/myenv/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/techlab/myenv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers) (12.4.99)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/techlab/myenv/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/techlab/myenv/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/techlab/myenv/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/techlab/myenv/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/techlab/myenv/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/techlab/myenv/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/techlab/myenv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/techlab/myenv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/techlab/myenv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/techlab/myenv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/techlab/myenv/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Collecting sentence-transformers==2.2.2\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /home/techlab/myenv/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (4.40.0)\n",
      "Requirement already satisfied: tqdm in /home/techlab/myenv/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (4.66.2)\n",
      "Requirement already satisfied: torch>=1.6.0 in /home/techlab/myenv/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (2.2.1)\n",
      "Collecting torchvision (from sentence-transformers==2.2.2)\n",
      "  Downloading torchvision-0.18.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: numpy in /home/techlab/myenv/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /home/techlab/myenv/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (1.4.1.post1)\n",
      "Requirement already satisfied: scipy in /home/techlab/myenv/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (1.12.0)\n",
      "Requirement already satisfied: nltk in /home/techlab/myenv/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (3.8.1)\n",
      "Collecting sentencepiece (from sentence-transformers==2.2.2)\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /home/techlab/myenv/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (0.22.2)\n",
      "Requirement already satisfied: filelock in /home/techlab/myenv/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/techlab/myenv/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2024.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/techlab/myenv/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/techlab/myenv/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (6.0.1)\n",
      "Requirement already satisfied: requests in /home/techlab/myenv/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/techlab/myenv/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (4.10.0)\n",
      "Requirement already satisfied: sympy in /home/techlab/myenv/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (1.12)\n",
      "Requirement already satisfied: networkx in /home/techlab/myenv/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/techlab/myenv/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/techlab/myenv/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/techlab/myenv/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/techlab/myenv/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/techlab/myenv/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/techlab/myenv/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/techlab/myenv/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/techlab/myenv/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/techlab/myenv/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/techlab/myenv/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/techlab/myenv/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/techlab/myenv/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/techlab/myenv/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/techlab/myenv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6.0->sentence-transformers==2.2.2) (12.4.99)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/techlab/myenv/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/techlab/myenv/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/techlab/myenv/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.4.3)\n",
      "Requirement already satisfied: click in /home/techlab/myenv/lib/python3.10/site-packages (from nltk->sentence-transformers==2.2.2) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/techlab/myenv/lib/python3.10/site-packages (from nltk->sentence-transformers==2.2.2) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/techlab/myenv/lib/python3.10/site-packages (from scikit-learn->sentence-transformers==2.2.2) (3.3.0)\n",
      "Collecting torch>=1.6.0 (from sentence-transformers==2.2.2)\n",
      "  Downloading torch-2.3.0-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/techlab/myenv/lib/python3.10/site-packages (from torchvision->sentence-transformers==2.2.2) (10.2.0)\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.6.0->sentence-transformers==2.2.2)\n",
      "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting triton==2.3.0 (from torch>=1.6.0->sentence-transformers==2.2.2)\n",
      "  Downloading triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/techlab/myenv/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence-transformers==2.2.2) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/techlab/myenv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/techlab/myenv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/techlab/myenv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/techlab/myenv/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/techlab/myenv/lib/python3.10/site-packages (from sympy->torch>=1.6.0->sentence-transformers==2.2.2) (1.3.0)\n",
      "Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.18.0-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.3.0-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: sentence-transformers\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=4fe7a6f590cc804605ae0659e1401e89c6caaeb5f1dbcfc4da9edba6994f9832\n",
      "  Stored in directory: /home/techlab/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
      "Successfully built sentence-transformers\n",
      "Installing collected packages: sentencepiece, triton, nvidia-nccl-cu12, torch, torchvision, sentence-transformers\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.2.0\n",
      "    Uninstalling triton-2.2.0:\n",
      "      Successfully uninstalled triton-2.2.0\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.19.3\n",
      "    Uninstalling nvidia-nccl-cu12-2.19.3:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.19.3\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.2.1\n",
      "    Uninstalling torch-2.2.1:\n",
      "      Successfully uninstalled torch-2.2.1\n",
      "  Attempting uninstall: sentence-transformers\n",
      "    Found existing installation: sentence-transformers 2.7.0\n",
      "    Uninstalling sentence-transformers-2.7.0:\n",
      "      Successfully uninstalled sentence-transformers-2.7.0\n",
      "Successfully installed nvidia-nccl-cu12-2.20.5 sentence-transformers-2.2.2 sentencepiece-0.2.0 torch-2.3.0 torchvision-0.18.0 triton-2.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U sentence-transformers\n",
    "!pip install -U sentence-transformers==2.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7060642-f65e-4e34-b55c-bf683af5ef9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unstructured in /home/techlab/myenv/lib/python3.10/site-packages (0.13.7)\n",
      "Requirement already satisfied: chardet in /home/techlab/myenv/lib/python3.10/site-packages (from unstructured) (5.2.0)\n",
      "Requirement already satisfied: filetype in /home/techlab/myenv/lib/python3.10/site-packages (from unstructured) (1.2.0)\n",
      "Requirement already satisfied: python-magic in /home/techlab/myenv/lib/python3.10/site-packages (from unstructured) (0.4.15)\n",
      "Requirement already satisfied: lxml in /home/techlab/myenv/lib/python3.10/site-packages (from unstructured) (5.1.0)\n",
      "Requirement already satisfied: nltk in /home/techlab/myenv/lib/python3.10/site-packages (from unstructured) (3.8.1)\n",
      "Requirement already satisfied: tabulate in /home/techlab/myenv/lib/python3.10/site-packages (from unstructured) (0.9.0)\n",
      "Requirement already satisfied: requests in /home/techlab/myenv/lib/python3.10/site-packages (from unstructured) (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/techlab/myenv/lib/python3.10/site-packages (from unstructured) (4.12.3)\n",
      "Requirement already satisfied: emoji in /home/techlab/myenv/lib/python3.10/site-packages (from unstructured) (2.11.1)\n",
      "Requirement already satisfied: dataclasses-json in /home/techlab/myenv/lib/python3.10/site-packages (from unstructured) (0.6.6)\n",
      "Requirement already satisfied: python-iso639 in /home/techlab/myenv/lib/python3.10/site-packages (from unstructured) (2024.4.27)\n",
      "Requirement already satisfied: langdetect in /home/techlab/myenv/lib/python3.10/site-packages (from unstructured) (1.0.9)\n",
      "Requirement already satisfied: numpy in /home/techlab/myenv/lib/python3.10/site-packages (from unstructured) (1.26.4)\n",
      "Requirement already satisfied: rapidfuzz in /home/techlab/myenv/lib/python3.10/site-packages (from unstructured) (3.9.0)\n",
      "Requirement already satisfied: backoff in /home/techlab/myenv/lib/python3.10/site-packages (from unstructured) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions in /home/techlab/myenv/lib/python3.10/site-packages (from unstructured) (4.10.0)\n",
      "Requirement already satisfied: unstructured-client in /home/techlab/myenv/lib/python3.10/site-packages (from unstructured) (0.22.0)\n",
      "Requirement already satisfied: wrapt in /home/techlab/myenv/lib/python3.10/site-packages (from unstructured) (1.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/techlab/myenv/lib/python3.10/site-packages (from beautifulsoup4->unstructured) (2.5)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/techlab/myenv/lib/python3.10/site-packages (from dataclasses-json->unstructured) (3.21.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/techlab/myenv/lib/python3.10/site-packages (from dataclasses-json->unstructured) (0.9.0)\n",
      "Requirement already satisfied: six in /home/techlab/myenv/lib/python3.10/site-packages (from langdetect->unstructured) (1.16.0)\n",
      "Requirement already satisfied: click in /home/techlab/myenv/lib/python3.10/site-packages (from nltk->unstructured) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/techlab/myenv/lib/python3.10/site-packages (from nltk->unstructured) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/techlab/myenv/lib/python3.10/site-packages (from nltk->unstructured) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in /home/techlab/myenv/lib/python3.10/site-packages (from nltk->unstructured) (4.66.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/techlab/myenv/lib/python3.10/site-packages (from requests->unstructured) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/techlab/myenv/lib/python3.10/site-packages (from requests->unstructured) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/techlab/myenv/lib/python3.10/site-packages (from requests->unstructured) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/techlab/myenv/lib/python3.10/site-packages (from requests->unstructured) (2024.2.2)\n",
      "Requirement already satisfied: deepdiff>=6.0 in /home/techlab/myenv/lib/python3.10/site-packages (from unstructured-client->unstructured) (7.0.1)\n",
      "Requirement already satisfied: jsonpath-python>=1.0.6 in /home/techlab/myenv/lib/python3.10/site-packages (from unstructured-client->unstructured) (1.0.6)\n",
      "Requirement already satisfied: mypy-extensions>=1.0.0 in /home/techlab/myenv/lib/python3.10/site-packages (from unstructured-client->unstructured) (1.0.0)\n",
      "Requirement already satisfied: packaging>=23.1 in /home/techlab/myenv/lib/python3.10/site-packages (from unstructured-client->unstructured) (23.2)\n",
      "Requirement already satisfied: pypdf>=4.0 in /home/techlab/myenv/lib/python3.10/site-packages (from unstructured-client->unstructured) (4.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/techlab/myenv/lib/python3.10/site-packages (from unstructured-client->unstructured) (2.9.0.post0)\n",
      "Requirement already satisfied: ordered-set<4.2.0,>=4.1.0 in /home/techlab/myenv/lib/python3.10/site-packages (from deepdiff>=6.0->unstructured-client->unstructured) (4.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d39523ef-3182-4f04-a545-bc6a3132aabb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaders = UnstructuredURLLoader(urls=[\n",
    "    \"https://www.moneycontrol.com/news/business/markets/wall-street-rises-as-tesla-soars-on-ai-optimism-11351111.html\",\n",
    "    \"https://www.moneycontrol.com/news/business/tata-motors-launches-punch-icng-price-starts-at-rs-7-1-lakh-11098751.html\"\n",
    "])\n",
    "data = loaders.load() \n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "557f2e83-f51e-4ce3-976a-0de84a7ac543",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "\n",
    "docs = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43c149a3-8f4a-4c36-8a87-5b60ed68d14e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1535d9da-c2db-4e94-8849-6e2bbdef0b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='English\\n\\nHindi\\n\\nGujarati\\n\\nSpecials\\n\\nMoneycontrol Trending Stock\\n\\nInfosys\\xa0INE009A01021, INFY, 500209\\n\\nState Bank of India\\xa0INE062A01020, SBIN, 500112\\n\\nYes Bank\\xa0INE528G01027, YESBANK, 532648\\n\\nBank Nifty\\n\\nNifty 500\\n\\nQuotes\\n\\nMutual Funds\\n\\nCommodities\\n\\nFutures & Options\\n\\nCurrency\\n\\nNews\\n\\nCryptocurrency\\n\\nForum\\n\\nNotices\\n\\nVideos\\n\\nGlossary\\n\\nAll\\n\\nHello, Login Hello, LoginLog-inor Sign-UpMy AccountMy Profile My PortfolioMy WatchlistFREE Credit Score₹100 Cash RewardMy AlertsMy MessagesPrice AlertsMy Profile My PROMy PortfolioMy WatchlistFREE Credit Score₹100 Cash RewardMy AlertsMy MessagesPrice AlertsLogoutChat with UsDownload AppFollow us on:\\n\\nPremium\\n\\nMy Alerts', metadata={'source': 'https://www.moneycontrol.com/news/business/markets/wall-street-rises-as-tesla-soars-on-ai-optimism-11351111.html'})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b331c6c0-6965-4b46-98a7-b7ac8322643f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d897638e-db6a-470e-b9ad-5e20eddb1c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir =\"/home/techlab/hong/LLMs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12e4fc87-6e3e-4d95-9bba-42d9e005a487",
   "metadata": {},
   "outputs": [],
   "source": [
    "path =f\"{root_dir}/Embedding_store\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e20d49f3-1d29-48b3-859f-ad54f3f36130",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceInstructEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5970a38-4f77-4637-8944-d0cf1a0de623",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "DEVICE =\"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6483a870-91b2-4451-9acb-1fc2706ed94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/techlab/myenv/lib/python3.10/site-packages/InstructorEmbedding/instructor.py:7: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import trange\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24e5b2939e9b4c86865b5321776db12e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/1.48k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c58b68d567c42f5945f3b87af6f82c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/270 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7a101440ae84a939ad6445e00a641ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "2_Dense/config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ce3620b7fd54cd3a194a48eecd0cab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/3.15M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b420d3f3455a4dc6891ed50da0bc1f1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/66.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ce01fe80ba84407b0102dbadba31d26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64da18a43c1345629171ffae33f62880",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52cf474994db4a7c9d8c4d1a1ab08033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/4.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6275e76c09684524a8d745d1d54710d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68c52df77d3f47809fcc916ea40bac28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac3f13b50d7a4343b9e48e6908b7600d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d41093ccd8db4f77a093e15e6428864c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac66c3d5926346929727d1b469cbaf43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.40k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfc37cf7b0c04c78bda71d184a47b633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/461 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "instruct_embedding =HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-xl\",model_kwargs={\"device\":DEVICE})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2b620852-32a7-4756-ae63-40419e684835",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pass the documents and embeddings o create FAISS vector index\n",
    "vectorIndex_instructEmbeddings =FAISS.from_documents(docs,instruct_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9db2981b-668c-47b9-b98b-187e6c410e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorIndex_instructEmbeddings.as_retriever(search_kwargs={\"k\":3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "71a8c5c7-caba-4085-b04d-b7e22e078bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'similarity'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.search_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bcebda02-a3a3-4f36-a30e-4ee7c2629695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_embeddings(docs,embeddings,store_name, path):\n",
    "    vectorStore =FAISS.from_documents(docs, embeddings)\n",
    "    with open(f\"{path}/faiss_{store_name}.pkl\",\"wb\")as f:\n",
    "              pickle.dump(vectorStore,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0b9c6352-d1e3-4f91-b7bd-a1d0b062658a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing vector index create in local memory\n",
    "#store_name =\"vector_index\"\n",
    "#store_embeddings(docs,vectorIndex_instructEmbeddings,store_name, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "91d756bb-e057-42fb-9410-bccb515408e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(store_name, path):\n",
    "    with open(f\"{path}/faiss_{store_name}.pkl\",\"rb\")as f:\n",
    "        vectorStore =pickle.load(f)\n",
    "    return vectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "69e1c438-3496-43e8-a284-42d98660e84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load vector index from the vector store\n",
    "#vectorIndex =load_embeddings(store_name, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3947f9dc-6e57-4962-8477-74445758851c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing vector index create in local\n",
    "file_path=\"vector_index.pkl\"\n",
    "with open(file_path, \"wb\") as f:\n",
    "    pickle.dump(vectorIndex_instructEmbeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "540c3832-be9c-4024-b1c2-b23e94cb03d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path, \"rb\") as f:\n",
    "    vectorIndex = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e65aedb4-43e5-4f94-b371-2d20f7b714bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve similar embeddings for a given question and call LLM to retrieve final answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "751fe166-c54a-4874-bab4-49541440d032",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what is the price of Tiago iCNG?\"\n",
    "docs_found =vectorIndex_instructEmbeddings.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f89d5c09-86eb-4ef9-93f5-7175ebc5e724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The company also said it has also introduced the twin-cylinder technology on its Tiago and Tigor models.\\n\\nThe Tiago iCNG is priced between Rs 6.55 lakh and Rs 8.1 lakh, while the Tigor iCNG comes at a price range of Rs 7.8 lakh to Rs 8.95 lakh.\\n\\nTata Motors Passenger Vehicles Ltd Head-Marketing, Vinay Pant said these introductions put together will make the company\\'s CNG line up \"appealing, holistic, and stronger than ever\".\\n\\nPTI\\n\\nTags:\\n\\n#Business\\n\\n#Companies\\n\\nfirst published: Aug 4, 2023 02:17 pm\\n\\nDiscover the latest business news, Sensex, and Nifty updates. Obtain Personal Finance insights, tax queries, and expert opinions on Moneycontrol or download the Moneycontrol App to stay updated!\\n\\nAdvertisement\\n\\nRemove Ad\\n\\nAdvertisement\\n\\nRemove Ad\\n\\nAdvertisement\\n\\nRemove Ad\\n\\nAdvertisement\\n\\nRemove Ad\\n\\nAdvertisement\\n\\nRemove Ad\\n\\nAdvertisement\\n\\nRemove Ad\\n\\nAdvisory Alert:\\n\\ngrievanceofficer@nw18.com or call on 02268882347\\n\\nForum\\n\\nFacebook\\n\\nTwitter\\n\\nInstagram\\n\\nLinkedin\\n\\nRSS\\n\\nPortfolio\\n\\nMarkets'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_found[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9725af23-9aa1-4266-92f1-7014b9caf694",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4ffaec49-7d33-4be2-890c-48ff5e59b7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_text_preserve_newlines(text, width =110):\n",
    "    lines =text.split(\"\\n\")\n",
    "    wrapped_lines =[textwrap.fill(line, width=width) for line in lines]\n",
    "    wrapped_text =\"\\n\".join(wrapped_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c3bce8ea-6926-48a8-8a53-202a15d7fb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(wrap_text_preserve_newlines(docs_found[0].page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "663c13cb-3692-4c8e-8cc0-67f37c6b1718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='The company also said it has also introduced the twin-cylinder technology on its Tiago and Tigor models.\\n\\nThe Tiago iCNG is priced between Rs 6.55 lakh and Rs 8.1 lakh, while the Tigor iCNG comes at a price range of Rs 7.8 lakh to Rs 8.95 lakh.\\n\\nTata Motors Passenger Vehicles Ltd Head-Marketing, Vinay Pant said these introductions put together will make the company\\'s CNG line up \"appealing, holistic, and stronger than ever\".\\n\\nPTI\\n\\nTags:\\n\\n#Business\\n\\n#Companies\\n\\nfirst published: Aug 4, 2023 02:17 pm\\n\\nDiscover the latest business news, Sensex, and Nifty updates. Obtain Personal Finance insights, tax queries, and expert opinions on Moneycontrol or download the Moneycontrol App to stay updated!\\n\\nAdvertisement\\n\\nRemove Ad\\n\\nAdvertisement\\n\\nRemove Ad\\n\\nAdvertisement\\n\\nRemove Ad\\n\\nAdvertisement\\n\\nRemove Ad\\n\\nAdvertisement\\n\\nRemove Ad\\n\\nAdvertisement\\n\\nRemove Ad\\n\\nAdvisory Alert:\\n\\ngrievanceofficer@nw18.com or call on 02268882347\\n\\nForum\\n\\nFacebook\\n\\nTwitter\\n\\nInstagram\\n\\nLinkedin\\n\\nRSS\\n\\nPortfolio\\n\\nMarkets', metadata={'source': 'https://www.moneycontrol.com/news/business/tata-motors-launches-punch-icng-price-starts-at-rs-7-1-lakh-11098751.html'})"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_found[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10645473-128e-4fec-ac15-6b337681ec89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create QA chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ea8c10c2-54bb-4d4b-afbf-c1c5d336d237",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dfc31f4f-24be-4743-8582-427c31ce0a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] =\"your HuggingFace_api_key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "35c50fb3-17a0-4a57-93ca-a1082d04b054",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm =HuggingFaceHub(repo_id=\"google/flan-t5-xl\", model_kwargs={\"temparature\":0,\"max_length\":512})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6f7f615b-a57b-48d8-a360-70ce375c5322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RetrievalQAWithSourcesChain(combine_documents_chain=MapReduceDocumentsChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['context', 'question'], template='Use the following portion of a long document to see if any of the text is relevant to answer the question. \\nReturn any relevant text verbatim.\\n{context}\\nQuestion: {question}\\nRelevant text, if any:'), llm=HuggingFaceHub(client=<InferenceClient(model='google/flan-t5-xl', timeout=None)>, repo_id='google/flan-t5-xl', task='text2text-generation', model_kwargs={'temparature': 0, 'max_length': 512})), reduce_documents_chain=ReduceDocumentsChain(combine_documents_chain=StuffDocumentsChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['question', 'summaries'], template='Given the following extracted parts of a long document and a question, create a final answer with references (\"SOURCES\"). \\nIf you don\\'t know the answer, just say that you don\\'t know. Don\\'t try to make up an answer.\\nALWAYS return a \"SOURCES\" part in your answer.\\n\\nQUESTION: Which state/country\\'s law governs the interpretation of the contract?\\n=========\\nContent: This Agreement is governed by English law and the parties submit to the exclusive jurisdiction of the English courts in  relation to any dispute (contractual or non-contractual) concerning this Agreement save that either party may apply to any court for an  injunction or other relief to protect its Intellectual Property Rights.\\nSource: 28-pl\\nContent: No Waiver. Failure or delay in exercising any right or remedy under this Agreement shall not constitute a waiver of such (or any other)  right or remedy.\\n\\n11.7 Severability. The invalidity, illegality or unenforceability of any term (or part of a term) of this Agreement shall not affect the continuation  in force of the remainder of the term (if any) and this Agreement.\\n\\n11.8 No Agency. Except as expressly stated otherwise, nothing in this Agreement shall create an agency, partnership or joint venture of any  kind between the parties.\\n\\n11.9 No Third-Party Beneficiaries.\\nSource: 30-pl\\nContent: (b) if Google believes, in good faith, that the Distributor has violated or caused Google to violate any Anti-Bribery Laws (as  defined in Clause 8.5) or that such a violation is reasonably likely to occur,\\nSource: 4-pl\\n=========\\nFINAL ANSWER: This Agreement is governed by English law.\\nSOURCES: 28-pl\\n\\nQUESTION: What did the president say about Michael Jackson?\\n=========\\nContent: Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and the Cabinet. Justices of the Supreme Court. My fellow Americans.  \\n\\nLast year COVID-19 kept us apart. This year we are finally together again. \\n\\nTonight, we meet as Democrats Republicans and Independents. But most importantly as Americans. \\n\\nWith a duty to one another to the American people to the Constitution. \\n\\nAnd with an unwavering resolve that freedom will always triumph over tyranny. \\n\\nSix days ago, Russia’s Vladimir Putin sought to shake the foundations of the free world thinking he could make it bend to his menacing ways. But he badly miscalculated. \\n\\nHe thought he could roll into Ukraine and the world would roll over. Instead he met a wall of strength he never imagined. \\n\\nHe met the Ukrainian people. \\n\\nFrom President Zelenskyy to every Ukrainian, their fearlessness, their courage, their determination, inspires the world. \\n\\nGroups of citizens blocking tanks with their bodies. Everyone from students to retirees teachers turned soldiers defending their homeland.\\nSource: 0-pl\\nContent: And we won’t stop. \\n\\nWe have lost so much to COVID-19. Time with one another. And worst of all, so much loss of life. \\n\\nLet’s use this moment to reset. Let’s stop looking at COVID-19 as a partisan dividing line and see it for what it is: A God-awful disease.  \\n\\nLet’s stop seeing each other as enemies, and start seeing each other for who we really are: Fellow Americans.  \\n\\nWe can’t change how divided we’ve been. But we can change how we move forward—on COVID-19 and other issues we must face together. \\n\\nI recently visited the New York City Police Department days after the funerals of Officer Wilbert Mora and his partner, Officer Jason Rivera. \\n\\nThey were responding to a 9-1-1 call when a man shot and killed them with a stolen gun. \\n\\nOfficer Mora was 27 years old. \\n\\nOfficer Rivera was 22. \\n\\nBoth Dominican Americans who’d grown up on the same streets they later chose to patrol as police officers. \\n\\nI spoke with their families and told them that we are forever in debt for their sacrifice, and we will carry on their mission to restore the trust and safety every community deserves.\\nSource: 24-pl\\nContent: And a proud Ukrainian people, who have known 30 years  of independence, have repeatedly shown that they will not tolerate anyone who tries to take their country backwards.  \\n\\nTo all Americans, I will be honest with you, as I’ve always promised. A Russian dictator, invading a foreign country, has costs around the world. \\n\\nAnd I’m taking robust action to make sure the pain of our sanctions  is targeted at Russia’s economy. And I will use every tool at our disposal to protect American businesses and consumers. \\n\\nTonight, I can announce that the United States has worked with 30 other countries to release 60 Million barrels of oil from reserves around the world.  \\n\\nAmerica will lead that effort, releasing 30 Million barrels from our own Strategic Petroleum Reserve. And we stand ready to do more if necessary, unified with our allies.  \\n\\nThese steps will help blunt gas prices here at home. And I know the news about what’s happening can seem alarming. \\n\\nBut I want you to know that we are going to be okay.\\nSource: 5-pl\\nContent: More support for patients and families. \\n\\nTo get there, I call on Congress to fund ARPA-H, the Advanced Research Projects Agency for Health. \\n\\nIt’s based on DARPA—the Defense Department project that led to the Internet, GPS, and so much more.  \\n\\nARPA-H will have a singular purpose—to drive breakthroughs in cancer, Alzheimer’s, diabetes, and more. \\n\\nA unity agenda for the nation. \\n\\nWe can do this. \\n\\nMy fellow Americans—tonight , we have gathered in a sacred space—the citadel of our democracy. \\n\\nIn this Capitol, generation after generation, Americans have debated great questions amid great strife, and have done great things. \\n\\nWe have fought for freedom, expanded liberty, defeated totalitarianism and terror. \\n\\nAnd built the strongest, freest, and most prosperous nation the world has ever known. \\n\\nNow is the hour. \\n\\nOur moment of responsibility. \\n\\nOur test of resolve and conscience, of history itself. \\n\\nIt is in this moment that our character is formed. Our purpose is found. Our future is forged. \\n\\nWell I know this nation.\\nSource: 34-pl\\n=========\\nFINAL ANSWER: The president did not mention Michael Jackson.\\nSOURCES:\\n\\nQUESTION: {question}\\n=========\\n{summaries}\\n=========\\nFINAL ANSWER:'), llm=HuggingFaceHub(client=<InferenceClient(model='google/flan-t5-xl', timeout=None)>, repo_id='google/flan-t5-xl', task='text2text-generation', model_kwargs={'temparature': 0, 'max_length': 512})), document_prompt=PromptTemplate(input_variables=['page_content', 'source'], template='Content: {page_content}\\nSource: {source}'), document_variable_name='summaries')), document_variable_name='context'), retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceInstructEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x709f7c2df610>))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = RetrievalQAWithSourcesChain.from_llm(llm=llm, retriever=vectorIndex.as_retriever())\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3d5d9373-9ba4-4ce7-8408-f47de78e5e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/techlab/myenv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RetrievalQAWithSourcesChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"what is the price of Tiago iCNG?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RetrievalQAWithSourcesChain > chain:MapReduceDocumentsChain] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RetrievalQAWithSourcesChain > chain:MapReduceDocumentsChain > chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input_list\": [\n",
      "    {\n",
      "      \"context\": \"The company also said it has also introduced the twin-cylinder technology on its Tiago and Tigor models.\\n\\nThe Tiago iCNG is priced between Rs 6.55 lakh and Rs 8.1 lakh, while the Tigor iCNG comes at a price range of Rs 7.8 lakh to Rs 8.95 lakh.\\n\\nTata Motors Passenger Vehicles Ltd Head-Marketing, Vinay Pant said these introductions put together will make the company's CNG line up \\\"appealing, holistic, and stronger than ever\\\".\\n\\nPTI\\n\\nTags:\\n\\n#Business\\n\\n#Companies\\n\\nfirst published: Aug 4, 2023 02:17 pm\\n\\nDiscover the latest business news, Sensex, and Nifty updates. Obtain Personal Finance insights, tax queries, and expert opinions on Moneycontrol or download the Moneycontrol App to stay updated!\\n\\nAdvertisement\\n\\nRemove Ad\\n\\nAdvertisement\\n\\nRemove Ad\\n\\nAdvertisement\\n\\nRemove Ad\\n\\nAdvertisement\\n\\nRemove Ad\\n\\nAdvertisement\\n\\nRemove Ad\\n\\nAdvertisement\\n\\nRemove Ad\\n\\nAdvisory Alert:\\n\\ngrievanceofficer@nw18.com or call on 02268882347\\n\\nForum\\n\\nFacebook\\n\\nTwitter\\n\\nInstagram\\n\\nLinkedin\\n\\nRSS\\n\\nPortfolio\\n\\nMarkets\",\n",
      "      \"question\": \"what is the price of Tiago iCNG?\"\n",
      "    },\n",
      "    {\n",
      "      \"context\": \"Go Ad-Free\\n\\nBusiness\\n\\nMarkets\\n\\nStocks\\n\\nEconomy\\n\\nCompanies\\n\\nTrends\\n\\nIPO\\n\\nOpinion\\n\\nEV Special\\n\\nHome\\n\\nNews\\n\\nBusiness\\n\\nTata Motors launches Punch iCNG, price starts at Rs 7.1 lakh\\n\\nThe Punch iCNG is equipped with the company's proprietary twin-cylinder technology with enhanced safety features like a micro-switch to keep the car switched off at the time of refuelling and thermal incident protection that cuts off CNG supply to the engine and releases gas into the atmosphere, Tata Motors said in a statement.\\n\\nPTI\\n\\nAugust 04, 2023 / 02:17 PM IST\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTata Motors launches Punch iCNG, price starts at Rs 7.1 lakh\\n\\nWatchlist\\n\\nPortfolio\\n\\nMessage\\n\\nSet Alert\\n\\nlive\\n\\nbselive\\n\\nnselive\\n\\nVolume \\n\\nTodays L/H \\n\\nMore\\n\\nTata Motors on Friday launched the CNG variant of its micro SUV Punch priced between Rs 7.1 lakh and Rs 9.68 lakh (ex-showroom, Delhi).\",\n",
      "      \"question\": \"what is the price of Tiago iCNG?\"\n",
      "    },\n",
      "    {\n",
      "      \"context\": \"Set Alert\\n\\nlive\\n\\nbselive\\n\\nnselive\\n\\nVolume \\n\\nTodays L/H \\n\\nMore\\n\\nTata Motors on Friday launched the CNG variant of its micro SUV Punch priced between Rs 7.1 lakh and Rs 9.68 lakh (ex-showroom, Delhi).\\n\\nThe Punch iCNG is equipped with the company's proprietary twin-cylinder technology with enhanced safety features like a micro-switch to keep the car switched off at the time of refuelling and thermal incident protection that cuts off CNG supply to the engine and releases gas into the atmosphere, Tata Motors said in a statement.\\n\\nStory continues below Advertisement\\n\\nRemove Ad\\n\\nIt is also equipped with other features such as voice assisted electric sunroof, automatic projector headlamps, LED DRLs, 16-inch diamond cut alloy wheels, 7-inch infotainment system by Harman that supports Android Auto and Apple Carplay connectivity, rain sensing wipers and height adjustable driver seat.\\n\\nThe company also said it has also introduced the twin-cylinder technology on its Tiago and Tigor models.\",\n",
      "      \"question\": \"what is the price of Tiago iCNG?\"\n",
      "    },\n",
      "    {\n",
      "      \"context\": \"CARDSHomePersonal Loan\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t Car Loan CalculatorHome Loan CalculatorEducation Loan CalculatorCredit Card Debit Payoff CalculatorTOOLSProvident Fund CalculatorAssets Allocation PlanningDebt Reduction PlannerDebt Evaluation CalculatorCurrent Expense CalculatorFREE CREDIT SCORE₹100 Cash RewardREAL ESTATE : TRENDS & ANALYTICSMC 30MONEYCONTROL - SECURENOW HEALTH INSURANCE RATINGSGOLD PRICE TODAYUpcoming Chat | Previous TranscriptsAll Schedule | Previous TranscriptForumEXPLORE FORUMHomepageMembership RulesForum TopicsAsk the ExpertTop BoardersUSER PROFILEFORUM TOPICSLatest ThreadsStocksIndexGoldPersonal FinanceJust PostedMF FORUMPOLLSLatest PollsHistorical PollsMarket SentimentsSUPPORTFAQsCode of ConductFeedbackWrite to usVideosVIDEOSHomepageVideos on DemandMarkets with Santo & CJMorning TradeCommodities chat with Manisha GuptaLet`s Talk JobsThe TenantDrive ReportBajar GupshupBits To BillionsPODCASTHomepagePodcast on DemandThe Week on Dalal StreetMarket MinutesMC Special PodcastSimply\",\n",
      "      \"question\": \"what is the price of Tiago iCNG?\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RetrievalQAWithSourcesChain > chain:MapReduceDocumentsChain > chain:LLMChain > llm:HuggingFaceHub] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Use the following portion of a long document to see if any of the text is relevant to answer the question. \\nReturn any relevant text verbatim.\\nThe company also said it has also introduced the twin-cylinder technology on its Tiago and Tigor models.\\n\\nThe Tiago iCNG is priced between Rs 6.55 lakh and Rs 8.1 lakh, while the Tigor iCNG comes at a price range of Rs 7.8 lakh to Rs 8.95 lakh.\\n\\nTata Motors Passenger Vehicles Ltd Head-Marketing, Vinay Pant said these introductions put together will make the company's CNG line up \\\"appealing, holistic, and stronger than ever\\\".\\n\\nPTI\\n\\nTags:\\n\\n#Business\\n\\n#Companies\\n\\nfirst published: Aug 4, 2023 02:17 pm\\n\\nDiscover the latest business news, Sensex, and Nifty updates. Obtain Personal Finance insights, tax queries, and expert opinions on Moneycontrol or download the Moneycontrol App to stay updated!\\n\\nAdvertisement\\n\\nRemove Ad\\n\\nAdvertisement\\n\\nRemove Ad\\n\\nAdvertisement\\n\\nRemove Ad\\n\\nAdvertisement\\n\\nRemove Ad\\n\\nAdvertisement\\n\\nRemove Ad\\n\\nAdvertisement\\n\\nRemove Ad\\n\\nAdvisory Alert:\\n\\ngrievanceofficer@nw18.com or call on 02268882347\\n\\nForum\\n\\nFacebook\\n\\nTwitter\\n\\nInstagram\\n\\nLinkedin\\n\\nRSS\\n\\nPortfolio\\n\\nMarkets\\nQuestion: what is the price of Tiago iCNG?\\nRelevant text, if any:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RetrievalQAWithSourcesChain > chain:MapReduceDocumentsChain > chain:LLMChain > llm:HuggingFaceHub] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Use the following portion of a long document to see if any of the text is relevant to answer the question. \\nReturn any relevant text verbatim.\\nGo Ad-Free\\n\\nBusiness\\n\\nMarkets\\n\\nStocks\\n\\nEconomy\\n\\nCompanies\\n\\nTrends\\n\\nIPO\\n\\nOpinion\\n\\nEV Special\\n\\nHome\\n\\nNews\\n\\nBusiness\\n\\nTata Motors launches Punch iCNG, price starts at Rs 7.1 lakh\\n\\nThe Punch iCNG is equipped with the company's proprietary twin-cylinder technology with enhanced safety features like a micro-switch to keep the car switched off at the time of refuelling and thermal incident protection that cuts off CNG supply to the engine and releases gas into the atmosphere, Tata Motors said in a statement.\\n\\nPTI\\n\\nAugust 04, 2023 / 02:17 PM IST\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTata Motors launches Punch iCNG, price starts at Rs 7.1 lakh\\n\\nWatchlist\\n\\nPortfolio\\n\\nMessage\\n\\nSet Alert\\n\\nlive\\n\\nbselive\\n\\nnselive\\n\\nVolume \\n\\nTodays L/H \\n\\nMore\\n\\nTata Motors on Friday launched the CNG variant of its micro SUV Punch priced between Rs 7.1 lakh and Rs 9.68 lakh (ex-showroom, Delhi).\\nQuestion: what is the price of Tiago iCNG?\\nRelevant text, if any:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RetrievalQAWithSourcesChain > chain:MapReduceDocumentsChain > chain:LLMChain > llm:HuggingFaceHub] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Use the following portion of a long document to see if any of the text is relevant to answer the question. \\nReturn any relevant text verbatim.\\nSet Alert\\n\\nlive\\n\\nbselive\\n\\nnselive\\n\\nVolume \\n\\nTodays L/H \\n\\nMore\\n\\nTata Motors on Friday launched the CNG variant of its micro SUV Punch priced between Rs 7.1 lakh and Rs 9.68 lakh (ex-showroom, Delhi).\\n\\nThe Punch iCNG is equipped with the company's proprietary twin-cylinder technology with enhanced safety features like a micro-switch to keep the car switched off at the time of refuelling and thermal incident protection that cuts off CNG supply to the engine and releases gas into the atmosphere, Tata Motors said in a statement.\\n\\nStory continues below Advertisement\\n\\nRemove Ad\\n\\nIt is also equipped with other features such as voice assisted electric sunroof, automatic projector headlamps, LED DRLs, 16-inch diamond cut alloy wheels, 7-inch infotainment system by Harman that supports Android Auto and Apple Carplay connectivity, rain sensing wipers and height adjustable driver seat.\\n\\nThe company also said it has also introduced the twin-cylinder technology on its Tiago and Tigor models.\\nQuestion: what is the price of Tiago iCNG?\\nRelevant text, if any:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RetrievalQAWithSourcesChain > chain:MapReduceDocumentsChain > chain:LLMChain > llm:HuggingFaceHub] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Use the following portion of a long document to see if any of the text is relevant to answer the question. \\nReturn any relevant text verbatim.\\nCARDSHomePersonal Loan\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t Car Loan CalculatorHome Loan CalculatorEducation Loan CalculatorCredit Card Debit Payoff CalculatorTOOLSProvident Fund CalculatorAssets Allocation PlanningDebt Reduction PlannerDebt Evaluation CalculatorCurrent Expense CalculatorFREE CREDIT SCORE₹100 Cash RewardREAL ESTATE : TRENDS & ANALYTICSMC 30MONEYCONTROL - SECURENOW HEALTH INSURANCE RATINGSGOLD PRICE TODAYUpcoming Chat | Previous TranscriptsAll Schedule | Previous TranscriptForumEXPLORE FORUMHomepageMembership RulesForum TopicsAsk the ExpertTop BoardersUSER PROFILEFORUM TOPICSLatest ThreadsStocksIndexGoldPersonal FinanceJust PostedMF FORUMPOLLSLatest PollsHistorical PollsMarket SentimentsSUPPORTFAQsCode of ConductFeedbackWrite to usVideosVIDEOSHomepageVideos on DemandMarkets with Santo & CJMorning TradeCommodities chat with Manisha GuptaLet`s Talk JobsThe TenantDrive ReportBajar GupshupBits To BillionsPODCASTHomepagePodcast on DemandThe Week on Dalal StreetMarket MinutesMC Special PodcastSimply\\nQuestion: what is the price of Tiago iCNG?\\nRelevant text, if any:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[31;1m\u001b[1;3m[llm/error]\u001b[0m \u001b[1m[chain:RetrievalQAWithSourcesChain > chain:MapReduceDocumentsChain > chain:LLMChain > llm:HuggingFaceHub] [312ms] LLM run errored with error:\n",
      "\u001b[0m\"BadRequestError(' (Request ID: DFgUAhAefSrZ8-G3BJLEb)\\\\n\\\\nBad request:\\\\nAuthorization header is correct, but the token seems invalid')Traceback (most recent call last):\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py\\\", line 304, in hf_raise_for_status\\n    response.raise_for_status()\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/requests/models.py\\\", line 1021, in raise_for_status\\n    raise HTTPError(http_error_msg, response=self)\\n\\n\\nrequests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api-inference.huggingface.co/models/google/flan-t5-xl\\n\\n\\n\\nThe above exception was the direct cause of the following exception:\\n\\n\\n\\nTraceback (most recent call last):\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain_core/language_models/llms.py\\\", line 657, in _generate_helper\\n    self._generate(\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain_core/language_models/llms.py\\\", line 1317, in _generate\\n    self._call(prompt, stop=stop, run_manager=run_manager, **kwargs)\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain_community/llms/huggingface_hub.py\\\", line 135, in _call\\n    response = self.client.post(\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/huggingface_hub/inference/_client.py\\\", line 267, in post\\n    hf_raise_for_status(response)\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py\\\", line 358, in hf_raise_for_status\\n    raise BadRequestError(message, response=response) from e\\n\\n\\nhuggingface_hub.utils._errors.BadRequestError:  (Request ID: DFgUAhAefSrZ8-G3BJLEb)\\n\\nBad request:\\nAuthorization header is correct, but the token seems invalid\"\n",
      "\u001b[31;1m\u001b[1;3m[llm/error]\u001b[0m \u001b[1m[chain:RetrievalQAWithSourcesChain > chain:MapReduceDocumentsChain > chain:LLMChain > llm:HuggingFaceHub] [312ms] LLM run errored with error:\n",
      "\u001b[0m\"BadRequestError(' (Request ID: DFgUAhAefSrZ8-G3BJLEb)\\\\n\\\\nBad request:\\\\nAuthorization header is correct, but the token seems invalid')Traceback (most recent call last):\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py\\\", line 304, in hf_raise_for_status\\n    response.raise_for_status()\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/requests/models.py\\\", line 1021, in raise_for_status\\n    raise HTTPError(http_error_msg, response=self)\\n\\n\\nrequests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api-inference.huggingface.co/models/google/flan-t5-xl\\n\\n\\n\\nThe above exception was the direct cause of the following exception:\\n\\n\\n\\nTraceback (most recent call last):\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain_core/language_models/llms.py\\\", line 657, in _generate_helper\\n    self._generate(\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain_core/language_models/llms.py\\\", line 1317, in _generate\\n    self._call(prompt, stop=stop, run_manager=run_manager, **kwargs)\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain_community/llms/huggingface_hub.py\\\", line 135, in _call\\n    response = self.client.post(\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/huggingface_hub/inference/_client.py\\\", line 267, in post\\n    hf_raise_for_status(response)\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py\\\", line 358, in hf_raise_for_status\\n    raise BadRequestError(message, response=response) from e\\n\\n\\nhuggingface_hub.utils._errors.BadRequestError:  (Request ID: DFgUAhAefSrZ8-G3BJLEb)\\n\\nBad request:\\nAuthorization header is correct, but the token seems invalid\"\n",
      "\u001b[31;1m\u001b[1;3m[llm/error]\u001b[0m \u001b[1m[chain:RetrievalQAWithSourcesChain > chain:MapReduceDocumentsChain > chain:LLMChain > llm:HuggingFaceHub] [312ms] LLM run errored with error:\n",
      "\u001b[0m\"BadRequestError(' (Request ID: DFgUAhAefSrZ8-G3BJLEb)\\\\n\\\\nBad request:\\\\nAuthorization header is correct, but the token seems invalid')Traceback (most recent call last):\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py\\\", line 304, in hf_raise_for_status\\n    response.raise_for_status()\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/requests/models.py\\\", line 1021, in raise_for_status\\n    raise HTTPError(http_error_msg, response=self)\\n\\n\\nrequests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api-inference.huggingface.co/models/google/flan-t5-xl\\n\\n\\n\\nThe above exception was the direct cause of the following exception:\\n\\n\\n\\nTraceback (most recent call last):\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain_core/language_models/llms.py\\\", line 657, in _generate_helper\\n    self._generate(\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain_core/language_models/llms.py\\\", line 1317, in _generate\\n    self._call(prompt, stop=stop, run_manager=run_manager, **kwargs)\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain_community/llms/huggingface_hub.py\\\", line 135, in _call\\n    response = self.client.post(\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/huggingface_hub/inference/_client.py\\\", line 267, in post\\n    hf_raise_for_status(response)\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py\\\", line 358, in hf_raise_for_status\\n    raise BadRequestError(message, response=response) from e\\n\\n\\nhuggingface_hub.utils._errors.BadRequestError:  (Request ID: DFgUAhAefSrZ8-G3BJLEb)\\n\\nBad request:\\nAuthorization header is correct, but the token seems invalid\"\n",
      "\u001b[31;1m\u001b[1;3m[llm/error]\u001b[0m \u001b[1m[chain:RetrievalQAWithSourcesChain > chain:MapReduceDocumentsChain > chain:LLMChain > llm:HuggingFaceHub] [312ms] LLM run errored with error:\n",
      "\u001b[0m\"BadRequestError(' (Request ID: DFgUAhAefSrZ8-G3BJLEb)\\\\n\\\\nBad request:\\\\nAuthorization header is correct, but the token seems invalid')Traceback (most recent call last):\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py\\\", line 304, in hf_raise_for_status\\n    response.raise_for_status()\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/requests/models.py\\\", line 1021, in raise_for_status\\n    raise HTTPError(http_error_msg, response=self)\\n\\n\\nrequests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api-inference.huggingface.co/models/google/flan-t5-xl\\n\\n\\n\\nThe above exception was the direct cause of the following exception:\\n\\n\\n\\nTraceback (most recent call last):\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain_core/language_models/llms.py\\\", line 657, in _generate_helper\\n    self._generate(\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain_core/language_models/llms.py\\\", line 1317, in _generate\\n    self._call(prompt, stop=stop, run_manager=run_manager, **kwargs)\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain_community/llms/huggingface_hub.py\\\", line 135, in _call\\n    response = self.client.post(\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/huggingface_hub/inference/_client.py\\\", line 267, in post\\n    hf_raise_for_status(response)\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py\\\", line 358, in hf_raise_for_status\\n    raise BadRequestError(message, response=response) from e\\n\\n\\nhuggingface_hub.utils._errors.BadRequestError:  (Request ID: DFgUAhAefSrZ8-G3BJLEb)\\n\\nBad request:\\nAuthorization header is correct, but the token seems invalid\"\n",
      "\u001b[31;1m\u001b[1;3m[chain/error]\u001b[0m \u001b[1m[chain:RetrievalQAWithSourcesChain > chain:MapReduceDocumentsChain > chain:LLMChain] [315ms] Chain run errored with error:\n",
      "\u001b[0m\"BadRequestError(' (Request ID: DFgUAhAefSrZ8-G3BJLEb)\\\\n\\\\nBad request:\\\\nAuthorization header is correct, but the token seems invalid')Traceback (most recent call last):\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py\\\", line 304, in hf_raise_for_status\\n    response.raise_for_status()\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/requests/models.py\\\", line 1021, in raise_for_status\\n    raise HTTPError(http_error_msg, response=self)\\n\\n\\nrequests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api-inference.huggingface.co/models/google/flan-t5-xl\\n\\n\\n\\nThe above exception was the direct cause of the following exception:\\n\\n\\n\\nTraceback (most recent call last):\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain/chains/llm.py\\\", line 247, in apply\\n    response = self.generate(input_list, run_manager=run_manager)\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain/chains/llm.py\\\", line 138, in generate\\n    return self.llm.generate_prompt(\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain_core/language_models/llms.py\\\", line 633, in generate_prompt\\n    return self.generate(prompt_strings, stop=stop, callbacks=callbacks, **kwargs)\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain_core/language_models/llms.py\\\", line 803, in generate\\n    output = self._generate_helper(\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain_core/language_models/llms.py\\\", line 670, in _generate_helper\\n    raise e\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain_core/language_models/llms.py\\\", line 657, in _generate_helper\\n    self._generate(\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain_core/language_models/llms.py\\\", line 1317, in _generate\\n    self._call(prompt, stop=stop, run_manager=run_manager, **kwargs)\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain_community/llms/huggingface_hub.py\\\", line 135, in _call\\n    response = self.client.post(\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/huggingface_hub/inference/_client.py\\\", line 267, in post\\n    hf_raise_for_status(response)\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py\\\", line 358, in hf_raise_for_status\\n    raise BadRequestError(message, response=response) from e\\n\\n\\nhuggingface_hub.utils._errors.BadRequestError:  (Request ID: DFgUAhAefSrZ8-G3BJLEb)\\n\\nBad request:\\nAuthorization header is correct, but the token seems invalid\"\n",
      "\u001b[31;1m\u001b[1;3m[chain/error]\u001b[0m \u001b[1m[chain:RetrievalQAWithSourcesChain > chain:MapReduceDocumentsChain] [323ms] Chain run errored with error:\n",
      "\u001b[0m\"BadRequestError(' (Request ID: DFgUAhAefSrZ8-G3BJLEb)\\\\n\\\\nBad request:\\\\nAuthorization header is correct, but the token seems invalid')Traceback (most recent call last):\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py\\\", line 304, in hf_raise_for_status\\n    response.raise_for_status()\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/requests/models.py\\\", line 1021, in raise_for_status\\n    raise HTTPError(http_error_msg, response=self)\\n\\n\\nrequests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api-inference.huggingface.co/models/google/flan-t5-xl\\n\\n\\n\\nThe above exception was the direct cause of the following exception:\\n\\n\\n\\nTraceback (most recent call last):\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain/chains/base.py\\\", line 153, in invoke\\n    self._call(inputs, run_manager=run_manager)\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain/chains/combine_documents/base.py\\\", line 137, in _call\\n    output, extra_return_dict = self.combine_docs(\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain/chains/combine_documents/map_reduce.py\\\", line 226, in combine_docs\\n    map_results = self.llm_chain.apply(\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain/chains/llm.py\\\", line 250, in apply\\n    raise e\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain/chains/llm.py\\\", line 247, in apply\\n    response = self.generate(input_list, run_manager=run_manager)\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain/chains/llm.py\\\", line 138, in generate\\n    return self.llm.generate_prompt(\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain_core/language_models/llms.py\\\", line 633, in generate_prompt\\n    return self.generate(prompt_strings, stop=stop, callbacks=callbacks, **kwargs)\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain_core/language_models/llms.py\\\", line 803, in generate\\n    output = self._generate_helper(\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain_core/language_models/llms.py\\\", line 670, in _generate_helper\\n    raise e\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain_core/language_models/llms.py\\\", line 657, in _generate_helper\\n    self._generate(\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain_core/language_models/llms.py\\\", line 1317, in _generate\\n    self._call(prompt, stop=stop, run_manager=run_manager, **kwargs)\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain_community/llms/huggingface_hub.py\\\", line 135, in _call\\n    response = self.client.post(\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/huggingface_hub/inference/_client.py\\\", line 267, in post\\n    hf_raise_for_status(response)\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py\\\", line 358, in hf_raise_for_status\\n    raise BadRequestError(message, response=response) from e\\n\\n\\nhuggingface_hub.utils._errors.BadRequestError:  (Request ID: DFgUAhAefSrZ8-G3BJLEb)\\n\\nBad request:\\nAuthorization header is correct, but the token seems invalid\"\n",
      "\u001b[31;1m\u001b[1;3m[chain/error]\u001b[0m \u001b[1m[chain:RetrievalQAWithSourcesChain] [735ms] Chain run errored with error:\n",
      "\u001b[0m\"BadRequestError(' (Request ID: DFgUAhAefSrZ8-G3BJLEb)\\\\n\\\\nBad request:\\\\nAuthorization header is correct, but the token seems invalid')Traceback (most recent call last):\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py\\\", line 304, in hf_raise_for_status\\n    response.raise_for_status()\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/requests/models.py\\\", line 1021, in raise_for_status\\n    raise HTTPError(http_error_msg, response=self)\\n\\n\\nrequests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api-inference.huggingface.co/models/google/flan-t5-xl\\n\\n\\n\\nThe above exception was the direct cause of the following exception:\\n\\n\\n\\nTraceback (most recent call last):\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain/chains/base.py\\\", line 153, in invoke\\n    self._call(inputs, run_manager=run_manager)\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain/chains/qa_with_sources/base.py\\\", line 156, in _call\\n    answer = self.combine_documents_chain.run(\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py\\\", line 148, in warning_emitting_wrapper\\n    return wrapped(*args, **kwargs)\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain/chains/base.py\\\", line 600, in run\\n    return self(kwargs, callbacks=callbacks, tags=tags, metadata=metadata)[\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py\\\", line 148, in warning_emitting_wrapper\\n    return wrapped(*args, **kwargs)\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain/chains/base.py\\\", line 378, in __call__\\n    return self.invoke(\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain/chains/base.py\\\", line 163, in invoke\\n    raise e\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain/chains/base.py\\\", line 153, in invoke\\n    self._call(inputs, run_manager=run_manager)\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain/chains/combine_documents/base.py\\\", line 137, in _call\\n    output, extra_return_dict = self.combine_docs(\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain/chains/combine_documents/map_reduce.py\\\", line 226, in combine_docs\\n    map_results = self.llm_chain.apply(\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain/chains/llm.py\\\", line 250, in apply\\n    raise e\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain/chains/llm.py\\\", line 247, in apply\\n    response = self.generate(input_list, run_manager=run_manager)\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain/chains/llm.py\\\", line 138, in generate\\n    return self.llm.generate_prompt(\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain_core/language_models/llms.py\\\", line 633, in generate_prompt\\n    return self.generate(prompt_strings, stop=stop, callbacks=callbacks, **kwargs)\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain_core/language_models/llms.py\\\", line 803, in generate\\n    output = self._generate_helper(\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain_core/language_models/llms.py\\\", line 670, in _generate_helper\\n    raise e\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain_core/language_models/llms.py\\\", line 657, in _generate_helper\\n    self._generate(\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain_core/language_models/llms.py\\\", line 1317, in _generate\\n    self._call(prompt, stop=stop, run_manager=run_manager, **kwargs)\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain_community/llms/huggingface_hub.py\\\", line 135, in _call\\n    response = self.client.post(\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/huggingface_hub/inference/_client.py\\\", line 267, in post\\n    hf_raise_for_status(response)\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py\\\", line 358, in hf_raise_for_status\\n    raise BadRequestError(message, response=response) from e\\n\\n\\nhuggingface_hub.utils._errors.BadRequestError:  (Request ID: DFgUAhAefSrZ8-G3BJLEb)\\n\\nBad request:\\nAuthorization header is correct, but the token seems invalid\"\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": " (Request ID: DFgUAhAefSrZ8-G3BJLEb)\n\nBad request:\nAuthorization header is correct, but the token seems invalid",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py:304\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 400 Client Error: Bad Request for url: https://api-inference.huggingface.co/models/google/flan-t5-xl",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[80], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# query = \"what are the main features of punch iCNG?\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m langchain\u001b[38;5;241m.\u001b[39mdebug\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[43mchain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:148\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     emit_warning()\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/langchain/chains/base.py:378\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[1;32m    347\u001b[0m \n\u001b[1;32m    348\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    371\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[1;32m    376\u001b[0m }\n\u001b[0;32m--> 378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/langchain/chains/base.py:163\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    162\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    164\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/langchain/chains/base.py:153\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    152\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 153\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    156\u001b[0m     )\n\u001b[1;32m    158\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    159\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    160\u001b[0m     )\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/langchain/chains/qa_with_sources/base.py:156\u001b[0m, in \u001b[0;36mBaseQAWithSourcesChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    154\u001b[0m     docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_docs(inputs)  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 156\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcombine_documents_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_documents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_run_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m answer, sources \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_sources(answer)\n\u001b[1;32m    160\u001b[0m result: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39manswer_key: answer,\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msources_answer_key: sources,\n\u001b[1;32m    163\u001b[0m }\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:148\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     emit_warning()\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/langchain/chains/base.py:600\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[1;32m    596\u001b[0m         _output_key\n\u001b[1;32m    597\u001b[0m     ]\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[0;32m--> 600\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m[\n\u001b[1;32m    601\u001b[0m         _output_key\n\u001b[1;32m    602\u001b[0m     ]\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m    605\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    606\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supported with either positional arguments or keyword arguments,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    607\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but none were provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    608\u001b[0m     )\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:148\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     emit_warning()\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/langchain/chains/base.py:378\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[1;32m    347\u001b[0m \n\u001b[1;32m    348\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    371\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[1;32m    376\u001b[0m }\n\u001b[0;32m--> 378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/langchain/chains/base.py:163\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    162\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    164\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/langchain/chains/base.py:153\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    152\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 153\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    156\u001b[0m     )\n\u001b[1;32m    158\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    159\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    160\u001b[0m     )\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/langchain/chains/combine_documents/base.py:137\u001b[0m, in \u001b[0;36mBaseCombineDocumentsChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# Other keys are assumed to be needed for LLM prediction\u001b[39;00m\n\u001b[1;32m    136\u001b[0m other_keys \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_key}\n\u001b[0;32m--> 137\u001b[0m output, extra_return_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcombine_docs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_run_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mother_keys\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m extra_return_dict[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key] \u001b[38;5;241m=\u001b[39m output\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m extra_return_dict\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/langchain/chains/combine_documents/map_reduce.py:226\u001b[0m, in \u001b[0;36mMapReduceDocumentsChain.combine_docs\u001b[0;34m(self, docs, token_max, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcombine_docs\u001b[39m(\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    216\u001b[0m     docs: List[Document],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    220\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mdict\u001b[39m]:\n\u001b[1;32m    221\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Combine documents in a map reduce manner.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \n\u001b[1;32m    223\u001b[0m \u001b[38;5;124;03m    Combine by mapping first chain over all documents, then reducing the results.\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;124;03m    This reducing can be done recursively if needed (if there are many documents).\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 226\u001b[0m     map_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# FYI - this is parallelized and so it is fast.\u001b[39;49;00m\n\u001b[1;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdocument_variable_name\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpage_content\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m     question_result_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_chain\u001b[38;5;241m.\u001b[39moutput_key\n\u001b[1;32m    232\u001b[0m     result_docs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    233\u001b[0m         Document(page_content\u001b[38;5;241m=\u001b[39mr[question_result_key], metadata\u001b[38;5;241m=\u001b[39mdocs[i]\u001b[38;5;241m.\u001b[39mmetadata)\n\u001b[1;32m    234\u001b[0m         \u001b[38;5;66;03m# This uses metadata from the docs, and the textual results from `results`\u001b[39;00m\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i, r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(map_results)\n\u001b[1;32m    236\u001b[0m     ]\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/langchain/chains/llm.py:250\u001b[0m, in \u001b[0;36mLLMChain.apply\u001b[0;34m(self, input_list, callbacks)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    249\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 250\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    251\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_outputs(response)\n\u001b[1;32m    252\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: outputs})\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/langchain/chains/llm.py:247\u001b[0m, in \u001b[0;36mLLMChain.apply\u001b[0;34m(self, input_list, callbacks)\u001b[0m\n\u001b[1;32m    242\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[1;32m    243\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    244\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_list\u001b[39m\u001b[38;5;124m\"\u001b[39m: input_list},\n\u001b[1;32m    245\u001b[0m )\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 247\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    249\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/langchain/chains/llm.py:138\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m    136\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m run_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm, BaseLanguageModel):\n\u001b[0;32m--> 138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    145\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mbind(stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_kwargs)\u001b[38;5;241m.\u001b[39mbatch(\n\u001b[1;32m    146\u001b[0m         cast(List, prompts), {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks}\n\u001b[1;32m    147\u001b[0m     )\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/langchain_core/language_models/llms.py:633\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    627\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    631\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    632\u001b[0m     prompt_strings \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_strings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/langchain_core/language_models/llms.py:803\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    789\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    790\u001b[0m         callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[1;32m    791\u001b[0m             dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    801\u001b[0m         )\n\u001b[1;32m    802\u001b[0m     ]\n\u001b[0;32m--> 803\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/langchain_core/language_models/llms.py:670\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n\u001b[1;32m    669\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 670\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    671\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m manager, flattened_output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(run_managers, flattened_outputs):\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/langchain_core/language_models/llms.py:657\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate_helper\u001b[39m(\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    649\u001b[0m     prompts: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    654\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    655\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    656\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 657\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[1;32m    661\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    664\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    665\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[1;32m    666\u001b[0m         )\n\u001b[1;32m    667\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    668\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/langchain_core/language_models/llms.py:1317\u001b[0m, in \u001b[0;36mLLM._generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1314\u001b[0m new_arg_supported \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1315\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[1;32m   1316\u001b[0m     text \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1317\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1318\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m   1319\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(prompt, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1320\u001b[0m     )\n\u001b[1;32m   1321\u001b[0m     generations\u001b[38;5;241m.\u001b[39mappend([Generation(text\u001b[38;5;241m=\u001b[39mtext)])\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations\u001b[38;5;241m=\u001b[39mgenerations)\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/langchain_community/llms/huggingface_hub.py:135\u001b[0m, in \u001b[0;36mHuggingFaceHub._call\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m _model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_kwargs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m    133\u001b[0m parameters \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_model_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[0;32m--> 135\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minputs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparameters\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m response \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mdecode())\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m response:\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/huggingface_hub/inference/_client.py:267\u001b[0m, in \u001b[0;36mInferenceClient.post\u001b[0;34m(self, json, data, model, task, stream)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InferenceTimeoutError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInference call timed out: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merror\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 267\u001b[0m     \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39miter_lines() \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m error:\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py:358\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m400\u001b[39m:\n\u001b[1;32m    355\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    356\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBad request for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mendpoint_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m endpoint:\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m endpoint_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBad request:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    357\u001b[0m     )\n\u001b[0;32m--> 358\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadRequestError(message, response\u001b[38;5;241m=\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m403\u001b[39m:\n\u001b[1;32m    361\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Forbidden: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_message\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    363\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCannot access content at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    364\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf you are trying to create or update content,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    365\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmake sure you have a token with the `write` role.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    366\u001b[0m     )\n",
      "\u001b[0;31mBadRequestError\u001b[0m:  (Request ID: DFgUAhAefSrZ8-G3BJLEb)\n\nBad request:\nAuthorization header is correct, but the token seems invalid"
     ]
    }
   ],
   "source": [
    "query = \"what is the price of Tiago iCNG?\"\n",
    "# query = \"what are the main features of punch iCNG?\"\n",
    "\n",
    "langchain.debug=True\n",
    "\n",
    "chain({\"question\": query}, return_only_outputs=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2980e846-a016-4f79-93a1-dd42e1899283",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5cda2b79-0251-4a11-b33d-e85b1248a8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create hthe chain to answerquestions\n",
    "qa_chain_instructEmbed =RetrievalQA.from_chain_type(llm=llm,\n",
    "                                                    chain_type=\"stuff\",\n",
    "                                                    retriever =retriever,\n",
    "                                                    return_source_documents=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0b8b977b-02f5-42e4-b465-abc246c575c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_llm_response(llm_response):\n",
    "    print(wrap_text_preserve_newlines(llm_response['result']))\n",
    "    print('\\nSources:')\n",
    "    for source in llm_response[\"source_documents\"]:\n",
    "        print(source.metadata['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7cb7583b-3972-47d5-8db6-90df718e71fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Instruct Embeddings --------------\n",
      "\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RetrievalQA] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"query\": \"what is the price of Tiago iCNG?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain > chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"what is the price of Tiago iCNG?\",\n",
      "  \"context\": \"The company also said it has also introduced the twin-cylinder technology on its Tiago and Tigor models.\\n\\nThe Tiago iCNG is priced between Rs 6.55 lakh and Rs 8.1 lakh, while the Tigor iCNG comes at a price range of Rs 7.8 lakh to Rs 8.95 lakh.\\n\\nTata Motors Passenger Vehicles Ltd Head-Marketing, Vinay Pant said these introductions put together will make the company's CNG line up \\\"appealing, holistic, and stronger than ever\\\".\\n\\nPTI\\n\\nTags:\\n\\n#Business\\n\\n#Companies\\n\\nfirst published: Aug 4, 2023 02:17 pm\\n\\nDiscover the latest business news, Sensex, and Nifty updates. Obtain Personal Finance insights, tax queries, and expert opinions on Moneycontrol or download the Moneycontrol App to stay updated!\\n\\nAdvertisement\\n\\nRemove Ad\\n\\nAdvertisement\\n\\nRemove Ad\\n\\nAdvertisement\\n\\nRemove Ad\\n\\nAdvertisement\\n\\nRemove Ad\\n\\nAdvertisement\\n\\nRemove Ad\\n\\nAdvertisement\\n\\nRemove Ad\\n\\nAdvisory Alert:\\n\\ngrievanceofficer@nw18.com or call on 02268882347\\n\\nForum\\n\\nFacebook\\n\\nTwitter\\n\\nInstagram\\n\\nLinkedin\\n\\nRSS\\n\\nPortfolio\\n\\nMarkets\\n\\nGo Ad-Free\\n\\nBusiness\\n\\nMarkets\\n\\nStocks\\n\\nEconomy\\n\\nCompanies\\n\\nTrends\\n\\nIPO\\n\\nOpinion\\n\\nEV Special\\n\\nHome\\n\\nNews\\n\\nBusiness\\n\\nTata Motors launches Punch iCNG, price starts at Rs 7.1 lakh\\n\\nThe Punch iCNG is equipped with the company's proprietary twin-cylinder technology with enhanced safety features like a micro-switch to keep the car switched off at the time of refuelling and thermal incident protection that cuts off CNG supply to the engine and releases gas into the atmosphere, Tata Motors said in a statement.\\n\\nPTI\\n\\nAugust 04, 2023 / 02:17 PM IST\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTata Motors launches Punch iCNG, price starts at Rs 7.1 lakh\\n\\nWatchlist\\n\\nPortfolio\\n\\nMessage\\n\\nSet Alert\\n\\nlive\\n\\nbselive\\n\\nnselive\\n\\nVolume \\n\\nTodays L/H \\n\\nMore\\n\\nTata Motors on Friday launched the CNG variant of its micro SUV Punch priced between Rs 7.1 lakh and Rs 9.68 lakh (ex-showroom, Delhi).\\n\\nSet Alert\\n\\nlive\\n\\nbselive\\n\\nnselive\\n\\nVolume \\n\\nTodays L/H \\n\\nMore\\n\\nTata Motors on Friday launched the CNG variant of its micro SUV Punch priced between Rs 7.1 lakh and Rs 9.68 lakh (ex-showroom, Delhi).\\n\\nThe Punch iCNG is equipped with the company's proprietary twin-cylinder technology with enhanced safety features like a micro-switch to keep the car switched off at the time of refuelling and thermal incident protection that cuts off CNG supply to the engine and releases gas into the atmosphere, Tata Motors said in a statement.\\n\\nStory continues below Advertisement\\n\\nRemove Ad\\n\\nIt is also equipped with other features such as voice assisted electric sunroof, automatic projector headlamps, LED DRLs, 16-inch diamond cut alloy wheels, 7-inch infotainment system by Harman that supports Android Auto and Apple Carplay connectivity, rain sensing wipers and height adjustable driver seat.\\n\\nThe company also said it has also introduced the twin-cylinder technology on its Tiago and Tigor models.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain > chain:LLMChain > llm:HuggingFaceHub] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\nThe company also said it has also introduced the twin-cylinder technology on its Tiago and Tigor models.\\n\\nThe Tiago iCNG is priced between Rs 6.55 lakh and Rs 8.1 lakh, while the Tigor iCNG comes at a price range of Rs 7.8 lakh to Rs 8.95 lakh.\\n\\nTata Motors Passenger Vehicles Ltd Head-Marketing, Vinay Pant said these introductions put together will make the company's CNG line up \\\"appealing, holistic, and stronger than ever\\\".\\n\\nPTI\\n\\nTags:\\n\\n#Business\\n\\n#Companies\\n\\nfirst published: Aug 4, 2023 02:17 pm\\n\\nDiscover the latest business news, Sensex, and Nifty updates. Obtain Personal Finance insights, tax queries, and expert opinions on Moneycontrol or download the Moneycontrol App to stay updated!\\n\\nAdvertisement\\n\\nRemove Ad\\n\\nAdvertisement\\n\\nRemove Ad\\n\\nAdvertisement\\n\\nRemove Ad\\n\\nAdvertisement\\n\\nRemove Ad\\n\\nAdvertisement\\n\\nRemove Ad\\n\\nAdvertisement\\n\\nRemove Ad\\n\\nAdvisory Alert:\\n\\ngrievanceofficer@nw18.com or call on 02268882347\\n\\nForum\\n\\nFacebook\\n\\nTwitter\\n\\nInstagram\\n\\nLinkedin\\n\\nRSS\\n\\nPortfolio\\n\\nMarkets\\n\\nGo Ad-Free\\n\\nBusiness\\n\\nMarkets\\n\\nStocks\\n\\nEconomy\\n\\nCompanies\\n\\nTrends\\n\\nIPO\\n\\nOpinion\\n\\nEV Special\\n\\nHome\\n\\nNews\\n\\nBusiness\\n\\nTata Motors launches Punch iCNG, price starts at Rs 7.1 lakh\\n\\nThe Punch iCNG is equipped with the company's proprietary twin-cylinder technology with enhanced safety features like a micro-switch to keep the car switched off at the time of refuelling and thermal incident protection that cuts off CNG supply to the engine and releases gas into the atmosphere, Tata Motors said in a statement.\\n\\nPTI\\n\\nAugust 04, 2023 / 02:17 PM IST\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTata Motors launches Punch iCNG, price starts at Rs 7.1 lakh\\n\\nWatchlist\\n\\nPortfolio\\n\\nMessage\\n\\nSet Alert\\n\\nlive\\n\\nbselive\\n\\nnselive\\n\\nVolume \\n\\nTodays L/H \\n\\nMore\\n\\nTata Motors on Friday launched the CNG variant of its micro SUV Punch priced between Rs 7.1 lakh and Rs 9.68 lakh (ex-showroom, Delhi).\\n\\nSet Alert\\n\\nlive\\n\\nbselive\\n\\nnselive\\n\\nVolume \\n\\nTodays L/H \\n\\nMore\\n\\nTata Motors on Friday launched the CNG variant of its micro SUV Punch priced between Rs 7.1 lakh and Rs 9.68 lakh (ex-showroom, Delhi).\\n\\nThe Punch iCNG is equipped with the company's proprietary twin-cylinder technology with enhanced safety features like a micro-switch to keep the car switched off at the time of refuelling and thermal incident protection that cuts off CNG supply to the engine and releases gas into the atmosphere, Tata Motors said in a statement.\\n\\nStory continues below Advertisement\\n\\nRemove Ad\\n\\nIt is also equipped with other features such as voice assisted electric sunroof, automatic projector headlamps, LED DRLs, 16-inch diamond cut alloy wheels, 7-inch infotainment system by Harman that supports Android Auto and Apple Carplay connectivity, rain sensing wipers and height adjustable driver seat.\\n\\nThe company also said it has also introduced the twin-cylinder technology on its Tiago and Tigor models.\\n\\nQuestion: what is the price of Tiago iCNG?\\nHelpful Answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[31;1m\u001b[1;3m[llm/error]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain > chain:LLMChain > llm:HuggingFaceHub] [240ms] LLM run errored with error:\n",
      "\u001b[0m\"BadRequestError(' (Request ID: Bj7-EkCGVkGLLJiPNeRMN)\\\\n\\\\nBad request:\\\\nAuthorization header is correct, but the token seems invalid')Traceback (most recent call last):\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py\\\", line 304, in hf_raise_for_status\\n    response.raise_for_status()\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/requests/models.py\\\", line 1021, in raise_for_status\\n    raise HTTPError(http_error_msg, response=self)\\n\\n\\nrequests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api-inference.huggingface.co/models/google/flan-t5-xl\\n\\n\\n\\nThe above exception was the direct cause of the following exception:\\n\\n\\n\\nTraceback (most recent call last):\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain_core/language_models/llms.py\\\", line 657, in _generate_helper\\n    self._generate(\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain_core/language_models/llms.py\\\", line 1317, in _generate\\n    self._call(prompt, stop=stop, run_manager=run_manager, **kwargs)\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain_community/llms/huggingface_hub.py\\\", line 135, in _call\\n    response = self.client.post(\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/huggingface_hub/inference/_client.py\\\", line 267, in post\\n    hf_raise_for_status(response)\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py\\\", line 358, in hf_raise_for_status\\n    raise BadRequestError(message, response=response) from e\\n\\n\\nhuggingface_hub.utils._errors.BadRequestError:  (Request ID: Bj7-EkCGVkGLLJiPNeRMN)\\n\\nBad request:\\nAuthorization header is correct, but the token seems invalid\"\n",
      "\u001b[31;1m\u001b[1;3m[chain/error]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain > chain:LLMChain] [242ms] Chain run errored with error:\n",
      "\u001b[0m\"BadRequestError(' (Request ID: Bj7-EkCGVkGLLJiPNeRMN)\\\\n\\\\nBad request:\\\\nAuthorization header is correct, but the token seems invalid')Traceback (most recent call last):\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py\\\", line 304, in hf_raise_for_status\\n    response.raise_for_status()\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/requests/models.py\\\", line 1021, in raise_for_status\\n    raise HTTPError(http_error_msg, response=self)\\n\\n\\nrequests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api-inference.huggingface.co/models/google/flan-t5-xl\\n\\n\\n\\nThe above exception was the direct cause of the following exception:\\n\\n\\n\\nTraceback (most recent call last):\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain/chains/base.py\\\", line 153, in invoke\\n    self._call(inputs, run_manager=run_manager)\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain/chains/llm.py\\\", line 126, in _call\\n    response = self.generate([inputs], run_manager=run_manager)\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain/chains/llm.py\\\", line 138, in generate\\n    return self.llm.generate_prompt(\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain_core/language_models/llms.py\\\", line 633, in generate_prompt\\n    return self.generate(prompt_strings, stop=stop, callbacks=callbacks, **kwargs)\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain_core/language_models/llms.py\\\", line 803, in generate\\n    output = self._generate_helper(\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain_core/language_models/llms.py\\\", line 670, in _generate_helper\\n    raise e\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain_core/language_models/llms.py\\\", line 657, in _generate_helper\\n    self._generate(\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain_core/language_models/llms.py\\\", line 1317, in _generate\\n    self._call(prompt, stop=stop, run_manager=run_manager, **kwargs)\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain_community/llms/huggingface_hub.py\\\", line 135, in _call\\n    response = self.client.post(\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/huggingface_hub/inference/_client.py\\\", line 267, in post\\n    hf_raise_for_status(response)\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py\\\", line 358, in hf_raise_for_status\\n    raise BadRequestError(message, response=response) from e\\n\\n\\nhuggingface_hub.utils._errors.BadRequestError:  (Request ID: Bj7-EkCGVkGLLJiPNeRMN)\\n\\nBad request:\\nAuthorization header is correct, but the token seems invalid\"\n",
      "\u001b[31;1m\u001b[1;3m[chain/error]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain] [251ms] Chain run errored with error:\n",
      "\u001b[0m\"BadRequestError(' (Request ID: Bj7-EkCGVkGLLJiPNeRMN)\\\\n\\\\nBad request:\\\\nAuthorization header is correct, but the token seems invalid')Traceback (most recent call last):\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py\\\", line 304, in hf_raise_for_status\\n    response.raise_for_status()\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/requests/models.py\\\", line 1021, in raise_for_status\\n    raise HTTPError(http_error_msg, response=self)\\n\\n\\nrequests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api-inference.huggingface.co/models/google/flan-t5-xl\\n\\n\\n\\nThe above exception was the direct cause of the following exception:\\n\\n\\n\\nTraceback (most recent call last):\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain/chains/base.py\\\", line 153, in invoke\\n    self._call(inputs, run_manager=run_manager)\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain/chains/combine_documents/base.py\\\", line 137, in _call\\n    output, extra_return_dict = self.combine_docs(\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain/chains/combine_documents/stuff.py\\\", line 244, in combine_docs\\n    return self.llm_chain.predict(callbacks=callbacks, **inputs), {}\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain/chains/llm.py\\\", line 316, in predict\\n    return self(kwargs, callbacks=callbacks)[self.output_key]\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py\\\", line 148, in warning_emitting_wrapper\\n    return wrapped(*args, **kwargs)\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain/chains/base.py\\\", line 378, in __call__\\n    return self.invoke(\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain/chains/base.py\\\", line 163, in invoke\\n    raise e\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain/chains/base.py\\\", line 153, in invoke\\n    self._call(inputs, run_manager=run_manager)\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain/chains/llm.py\\\", line 126, in _call\\n    response = self.generate([inputs], run_manager=run_manager)\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain/chains/llm.py\\\", line 138, in generate\\n    return self.llm.generate_prompt(\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain_core/language_models/llms.py\\\", line 633, in generate_prompt\\n    return self.generate(prompt_strings, stop=stop, callbacks=callbacks, **kwargs)\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain_core/language_models/llms.py\\\", line 803, in generate\\n    output = self._generate_helper(\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain_core/language_models/llms.py\\\", line 670, in _generate_helper\\n    raise e\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain_core/language_models/llms.py\\\", line 657, in _generate_helper\\n    self._generate(\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain_core/language_models/llms.py\\\", line 1317, in _generate\\n    self._call(prompt, stop=stop, run_manager=run_manager, **kwargs)\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain_community/llms/huggingface_hub.py\\\", line 135, in _call\\n    response = self.client.post(\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/huggingface_hub/inference/_client.py\\\", line 267, in post\\n    hf_raise_for_status(response)\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py\\\", line 358, in hf_raise_for_status\\n    raise BadRequestError(message, response=response) from e\\n\\n\\nhuggingface_hub.utils._errors.BadRequestError:  (Request ID: Bj7-EkCGVkGLLJiPNeRMN)\\n\\nBad request:\\nAuthorization header is correct, but the token seems invalid\"\n",
      "\u001b[31;1m\u001b[1;3m[chain/error]\u001b[0m \u001b[1m[chain:RetrievalQA] [728ms] Chain run errored with error:\n",
      "\u001b[0m\"BadRequestError(' (Request ID: Bj7-EkCGVkGLLJiPNeRMN)\\\\n\\\\nBad request:\\\\nAuthorization header is correct, but the token seems invalid')Traceback (most recent call last):\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py\\\", line 304, in hf_raise_for_status\\n    response.raise_for_status()\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/requests/models.py\\\", line 1021, in raise_for_status\\n    raise HTTPError(http_error_msg, response=self)\\n\\n\\nrequests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api-inference.huggingface.co/models/google/flan-t5-xl\\n\\n\\n\\nThe above exception was the direct cause of the following exception:\\n\\n\\n\\nTraceback (most recent call last):\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain/chains/base.py\\\", line 153, in invoke\\n    self._call(inputs, run_manager=run_manager)\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain/chains/retrieval_qa/base.py\\\", line 145, in _call\\n    answer = self.combine_documents_chain.run(\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py\\\", line 148, in warning_emitting_wrapper\\n    return wrapped(*args, **kwargs)\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain/chains/base.py\\\", line 600, in run\\n    return self(kwargs, callbacks=callbacks, tags=tags, metadata=metadata)[\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py\\\", line 148, in warning_emitting_wrapper\\n    return wrapped(*args, **kwargs)\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain/chains/base.py\\\", line 378, in __call__\\n    return self.invoke(\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain/chains/base.py\\\", line 163, in invoke\\n    raise e\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain/chains/base.py\\\", line 153, in invoke\\n    self._call(inputs, run_manager=run_manager)\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain/chains/combine_documents/base.py\\\", line 137, in _call\\n    output, extra_return_dict = self.combine_docs(\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain/chains/combine_documents/stuff.py\\\", line 244, in combine_docs\\n    return self.llm_chain.predict(callbacks=callbacks, **inputs), {}\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain/chains/llm.py\\\", line 316, in predict\\n    return self(kwargs, callbacks=callbacks)[self.output_key]\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py\\\", line 148, in warning_emitting_wrapper\\n    return wrapped(*args, **kwargs)\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain/chains/base.py\\\", line 378, in __call__\\n    return self.invoke(\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain/chains/base.py\\\", line 163, in invoke\\n    raise e\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain/chains/base.py\\\", line 153, in invoke\\n    self._call(inputs, run_manager=run_manager)\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain/chains/llm.py\\\", line 126, in _call\\n    response = self.generate([inputs], run_manager=run_manager)\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain/chains/llm.py\\\", line 138, in generate\\n    return self.llm.generate_prompt(\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain_core/language_models/llms.py\\\", line 633, in generate_prompt\\n    return self.generate(prompt_strings, stop=stop, callbacks=callbacks, **kwargs)\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain_core/language_models/llms.py\\\", line 803, in generate\\n    output = self._generate_helper(\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain_core/language_models/llms.py\\\", line 670, in _generate_helper\\n    raise e\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain_core/language_models/llms.py\\\", line 657, in _generate_helper\\n    self._generate(\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain_core/language_models/llms.py\\\", line 1317, in _generate\\n    self._call(prompt, stop=stop, run_manager=run_manager, **kwargs)\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/langchain_community/llms/huggingface_hub.py\\\", line 135, in _call\\n    response = self.client.post(\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/huggingface_hub/inference/_client.py\\\", line 267, in post\\n    hf_raise_for_status(response)\\n\\n\\n  File \\\"/home/techlab/myenv/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py\\\", line 358, in hf_raise_for_status\\n    raise BadRequestError(message, response=response) from e\\n\\n\\nhuggingface_hub.utils._errors.BadRequestError:  (Request ID: Bj7-EkCGVkGLLJiPNeRMN)\\n\\nBad request:\\nAuthorization header is correct, but the token seems invalid\"\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": " (Request ID: Bj7-EkCGVkGLLJiPNeRMN)\n\nBad request:\nAuthorization header is correct, but the token seems invalid",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py:304\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 400 Client Error: Bad Request for url: https://api-inference.huggingface.co/models/google/flan-t5-xl",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhat is the price of Tiago iCNG?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-----------Instruct Embeddings --------------\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m llm_response \u001b[38;5;241m=\u001b[39m\u001b[43mqa_chain_instructEmbed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m process_llm_response(llm_response)\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:148\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     emit_warning()\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/langchain/chains/base.py:378\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[1;32m    347\u001b[0m \n\u001b[1;32m    348\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    371\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[1;32m    376\u001b[0m }\n\u001b[0;32m--> 378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/langchain/chains/base.py:163\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    162\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    164\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/langchain/chains/base.py:153\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    152\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 153\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    156\u001b[0m     )\n\u001b[1;32m    158\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    159\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    160\u001b[0m     )\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/langchain/chains/retrieval_qa/base.py:145\u001b[0m, in \u001b[0;36mBaseRetrievalQA._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_docs(question)  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 145\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcombine_documents_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_documents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_run_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_source_documents:\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key: answer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource_documents\u001b[39m\u001b[38;5;124m\"\u001b[39m: docs}\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:148\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     emit_warning()\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/langchain/chains/base.py:600\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[1;32m    596\u001b[0m         _output_key\n\u001b[1;32m    597\u001b[0m     ]\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[0;32m--> 600\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m[\n\u001b[1;32m    601\u001b[0m         _output_key\n\u001b[1;32m    602\u001b[0m     ]\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m    605\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    606\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supported with either positional arguments or keyword arguments,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    607\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but none were provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    608\u001b[0m     )\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:148\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     emit_warning()\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/langchain/chains/base.py:378\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[1;32m    347\u001b[0m \n\u001b[1;32m    348\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    371\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[1;32m    376\u001b[0m }\n\u001b[0;32m--> 378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/langchain/chains/base.py:163\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    162\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    164\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/langchain/chains/base.py:153\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    152\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 153\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    156\u001b[0m     )\n\u001b[1;32m    158\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    159\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    160\u001b[0m     )\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/langchain/chains/combine_documents/base.py:137\u001b[0m, in \u001b[0;36mBaseCombineDocumentsChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# Other keys are assumed to be needed for LLM prediction\u001b[39;00m\n\u001b[1;32m    136\u001b[0m other_keys \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_key}\n\u001b[0;32m--> 137\u001b[0m output, extra_return_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcombine_docs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_run_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mother_keys\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m extra_return_dict[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key] \u001b[38;5;241m=\u001b[39m output\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m extra_return_dict\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/langchain/chains/combine_documents/stuff.py:244\u001b[0m, in \u001b[0;36mStuffDocumentsChain.combine_docs\u001b[0;34m(self, docs, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    242\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_inputs(docs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    243\u001b[0m \u001b[38;5;66;03m# Call predict on the LLM.\u001b[39;00m\n\u001b[0;32m--> 244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m, {}\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/langchain/chains/llm.py:316\u001b[0m, in \u001b[0;36mLLMChain.predict\u001b[0;34m(self, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, callbacks: Callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    302\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Format prompt with kwargs and pass to LLM.\u001b[39;00m\n\u001b[1;32m    303\u001b[0m \n\u001b[1;32m    304\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;124;03m            completion = llm.predict(adjective=\"funny\")\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key]\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:148\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     emit_warning()\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/langchain/chains/base.py:378\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[1;32m    347\u001b[0m \n\u001b[1;32m    348\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    371\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[1;32m    376\u001b[0m }\n\u001b[0;32m--> 378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/langchain/chains/base.py:163\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    162\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    164\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/langchain/chains/base.py:153\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    152\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 153\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    156\u001b[0m     )\n\u001b[1;32m    158\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    159\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    160\u001b[0m     )\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/langchain/chains/llm.py:126\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    123\u001b[0m     inputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m    124\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    125\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m--> 126\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_outputs(response)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/langchain/chains/llm.py:138\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m    136\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m run_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm, BaseLanguageModel):\n\u001b[0;32m--> 138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    145\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mbind(stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_kwargs)\u001b[38;5;241m.\u001b[39mbatch(\n\u001b[1;32m    146\u001b[0m         cast(List, prompts), {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks}\n\u001b[1;32m    147\u001b[0m     )\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/langchain_core/language_models/llms.py:633\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    627\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    631\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    632\u001b[0m     prompt_strings \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_strings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/langchain_core/language_models/llms.py:803\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    789\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    790\u001b[0m         callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[1;32m    791\u001b[0m             dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    801\u001b[0m         )\n\u001b[1;32m    802\u001b[0m     ]\n\u001b[0;32m--> 803\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/langchain_core/language_models/llms.py:670\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n\u001b[1;32m    669\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 670\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    671\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m manager, flattened_output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(run_managers, flattened_outputs):\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/langchain_core/language_models/llms.py:657\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate_helper\u001b[39m(\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    649\u001b[0m     prompts: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    654\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    655\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    656\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 657\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[1;32m    661\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    664\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    665\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[1;32m    666\u001b[0m         )\n\u001b[1;32m    667\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    668\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/langchain_core/language_models/llms.py:1317\u001b[0m, in \u001b[0;36mLLM._generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1314\u001b[0m new_arg_supported \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1315\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[1;32m   1316\u001b[0m     text \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1317\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1318\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m   1319\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(prompt, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1320\u001b[0m     )\n\u001b[1;32m   1321\u001b[0m     generations\u001b[38;5;241m.\u001b[39mappend([Generation(text\u001b[38;5;241m=\u001b[39mtext)])\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations\u001b[38;5;241m=\u001b[39mgenerations)\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/langchain_community/llms/huggingface_hub.py:135\u001b[0m, in \u001b[0;36mHuggingFaceHub._call\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m _model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_kwargs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m    133\u001b[0m parameters \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_model_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[0;32m--> 135\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minputs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparameters\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m response \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mdecode())\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m response:\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/huggingface_hub/inference/_client.py:267\u001b[0m, in \u001b[0;36mInferenceClient.post\u001b[0;34m(self, json, data, model, task, stream)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InferenceTimeoutError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInference call timed out: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merror\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 267\u001b[0m     \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39miter_lines() \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m error:\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py:358\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m400\u001b[39m:\n\u001b[1;32m    355\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    356\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBad request for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mendpoint_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m endpoint:\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m endpoint_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBad request:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    357\u001b[0m     )\n\u001b[0;32m--> 358\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadRequestError(message, response\u001b[38;5;241m=\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m403\u001b[39m:\n\u001b[1;32m    361\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Forbidden: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_message\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    363\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCannot access content at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    364\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf you are trying to create or update content,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    365\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmake sure you have a token with the `write` role.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    366\u001b[0m     )\n",
      "\u001b[0;31mBadRequestError\u001b[0m:  (Request ID: Bj7-EkCGVkGLLJiPNeRMN)\n\nBad request:\nAuthorization header is correct, but the token seems invalid"
     ]
    }
   ],
   "source": [
    "query = \"what is the price of Tiago iCNG?\"\n",
    "print('-----------Instruct Embeddings --------------\\n')\n",
    "llm_response =qa_chain_instructEmbed(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27899959-e086-49af-8c4c-9a5236cd53f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fd5d7b0e-2718-4a10-b6e5-0a4c1275f40e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Response' object has no attribute 'txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m res\u001b[38;5;241m=\u001b[39mrequests\u001b[38;5;241m.\u001b[39mget(url)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate+of_the_union,txt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 5\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(\u001b[43mres\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtxt\u001b[49m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Response' object has no attribute 'txt'"
     ]
    }
   ],
   "source": [
    "''' #another way to extract text from url\n",
    "import requests\n",
    "url =\"https://raw.githubusercontent.com/hwchase17/langchain/master/docs/modules/state_of_the_union.txt\"\n",
    "res=requests.get(url)\n",
    "with open(\"state+of_the_union,txt\",\"w\") as f:\n",
    "    f.write(res.txt)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839884b2-24c7-419e-98cb-6c9fc543e0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chain = RetrievalQAWithSourcesChain.from_llm(llm=llm, retriever=vectorIndex.as_retriever())\n",
    "#chain"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
